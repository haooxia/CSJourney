# 测试开发八股

> 一直都有机会，一直都来得及，别眼高手低，沉下去。

## 一、测试基础

### 0. 对测试/测开的理解

1. 测试不仅要找错误，还要验证软件的功能、性能、可靠性和用户体验
2. 测试可以提前找到bug，减少维护成本，提升用户满意度

为什么投测开？而非开发？

1. 测开方位很重要，减小公司损失
2. 岗位需求比较大，前景好
3. 也是需要开发来提高测试效率的
4. 我对于找到bug并解决很有成就感

### 1. 软件测试分类

1. 按是否查看代码划分
   1. **白盒测试**：又称为**逻辑驱动测试**，测试者了解系统内部结构和代码，关注逻辑和实现细节。是一种**接口测试**。
   2. **黑盒测试**：又称为数据驱动测试/**功能测试**、把被测软件当成一个黑盒子，测试者不关心内部结构，只根据输入和预期输出验证功能。
   3. **灰盒测试**：介于二者之间，测试者部分了解内部结构，但主要以功能测试为主。灰盒测试多用于**集成测试阶段**。
2. 从是否执行代码划分
   1. **静态测试**：不运行代码，仅通过分析或检查源程序的语法、结构、文档等来发现问题。
   2. **动态测试**：运行代码，检查结果是否符合预期，并分析运行效率、正确性和健壮性等性能指标。（一般都是动态测试）
      1. 动态测试由三部分组成：**构造测试用例、执行程序、分析程序的输出结果**。
3. 从开发阶段看
   1. **单元测试**：测试**单个模块**(eg 一个计算税率函数，一个数据库查询逻辑)，确保其独立功能正确。通常由**开发人员**进行。
   2. **集成测试**：也称联合测试：测试**多个模块组合**后的协作，验证它们能否正常交互。
      1. 单元测试是一个模块内部的测试，集成测试是在模块之间进行测试（至少两个）
   3. **系统测试**：将软件系统看成是一个系统的测试。包括对功能、性能以及软件所运行的软硬件环境进行测试。系统测试包括**回归测试和冒烟测试**。
      1. 严格的顺序：**==先冒烟、再系统、后回归==**。
      2. **冒烟测试**(smoke testing)：在对新版本进行大规模的测试之前，**快速检查系统主要功能是否正常运行**，像“点个火看看机器能不能转”一样。如果冒烟不通过，就不浪费时间往后走。
      4. 系统测试：全面、完整测试（功能、性能、安全...），**大体检**。
      5. **回归测试**（Regression Testing）：是指对软件的新的版本测试时，**重复执行上一个版本测试时的用例**。以**确认修改后原有功能还正常工作**。
   4. **验收测试**: **由用户或客户进行**，确认系统是否满足最终需求和合同要求，通常是**交付前的最后一步**。
   5. 注意：单元测试属于**白**盒测试；集成测试属于**灰**盒测试；系统测试和验收测试属于**黑**盒测试。（越高层越抽象咯）
4. 从执行过程是否需要人工干预来看
   1. **手工测试**：测试人员手动执行测试案例，比如点击按钮、输入测试数据、检查记录结果。优点：灵活，适合一次性场景。缺点：累人，低效。
   2. **自动化测试**：用自动化测试工具或脚本模拟手动测试步骤，检查是否符合预期。优点：高效、快。缺点：编写脚本成本高。
5. 其他测试类型：
   1. 随机测试：随机生成输入数据，模拟用户的真实操作，可能发现一些边缘性的错误。
   2. α测试：对软件最初版本进行测试。最初版本一般不对外发布，由开发、测试人员测试，可控。
   3. β测试：上线后对软件测试，发布的版本可能会有小bug，用户可以发现错误反馈给开发。
6. 按照测试的手段分类：
   1. **功能测试**：一般指黑盒测试
   2. **接口测试**：指服务端的功能测试
   3. **性能测试**：包含客户端和服务端的性能测试
   4. **安全测试**：敏感数据测试(数据加密)，防止黑客攻击(漏洞扫描、渗透测试)等测试

### 2. 设计测试用例（黑盒）

1. **等价类划分**：将系统的输入域划分为若干部分（因为你想穷举，时间成本上不现实且没必要），然后从每个部分选少量代表性数据进行测试。该方法认为如果一个测试用例在某个**等价类**中的一个值上通过测试，则在该类中其他值也可以通过。比如输入年龄，0-100是有效类，负数是无效类。
   1. **有效等价类**：符合规格说明的输入数据
   2. **无效等价类**：不符合规格说明的输入数据
   3. 通过测试有效等价类验证系统的**正确性**，通过无效等价类测试系统的**健壮性**
2. **边界值分析法**：大量错误是发生在输入输出范围的边界上，选定测试用例时应该选取**正好等于、刚刚大于(+1)、刚刚小于(-1)边界值**的值作为测试数据，而非选取等价类中的任意值。
   1. 比如年龄输入范围规定0-100,你测-1,0,1,99,100,101
3. **错误推测法**：凭**经验猜**哪里容易出错，针对性设计用例。比如输入特殊字符，看系统会不会崩。
4. **场景法**：模拟用户实际使用流程设计用例，比如电商下单：浏览→加购物车→支付，覆盖典型操作。这样设计就可以看看整个流程有毛病没。

### 3. CI/CD

CI/CD是一个软件开发流程：编译 -> 测试 -> 部署

* CI: Continuous Integration (CI) 持续集成
* CD: Continuous Delivery / Continous Deployment 持续交付和持续部署

* **持续集成**：开发人员将代码 **==频繁地合并==**/集成到**主代码库**中（通常每天多次），并通过**自动化构建和测试**来验证代码的正确性。核心思想是尽早发现问题，避免开发人员长期在各自的分支上工作，最终合并时出现大量冲突或问题。**早发现、少翻车**。
  * **自动化构建**(编译代码、打包、生成可运行版本)：每次提交代码，持续集成系统会自动拉取代码库最新版本，进行构建。开发人员可以快速发现构建过程可能出现的依赖问题或编译错误。
  * **自动化测试**：构建好后，持续集成系统会**自动运行预先编写好的测试用例**，确保代码逻辑正确。尽早发现和解决问题。
  * 即自动化构建是“造东西”，把代码编程产品。自动化测试是“验东西”，检查产品有毛病没。
* **持续交付**：持续集成后，自动部署代码到预发布环境进行进一步的测试和评估。想上线需要**人工手动发布**
* **持续部署**：**比持续交付更狠一点**，代码通过测试后自动上线给用户用，不用人干预，像流水线直接出货。（前提是你的自动化测试够牛逼，现实中一般先持续交付再持续部署，风险低点

![picture 0](../images/23b48f08bdb6899d8e30e50408f4df13bee28b8791d2c63a3c32176e746d8a2b.png)  


> 丢个图放这儿，DevOps全流程，了解了解，涉及到CICD，云计算，部署等

## 测试用例设计

### 百度搜索框

1. 功能测试
   1. 正常业务流程
      1. 测试推荐相关性：输入常见关键词，比如“天气”“新闻”，验证搜索结果是否准确且相关
      2. 测试搜索推荐：输入时是否有智能搜索推荐/搜索建议功能，eg 输入'北'，提示北京
      3. 输入长度最大范围限制
   2. 异常测试
      1. 无网络状态下搜索，应该提示用户检查网络连接
      2. 弱网络下(<2G的速率)，应提示“网络不稳定，稍后重试”
2. 性能测试
   1. 搜索后页面响应时间（不能太长吧，eg 1s内）
   2. 多用户并发搜索操作 页面响应时间
   3. 极限并发用户负载下，系统稳定性表现
3. 兼容性测试
   1. 不同os，linux win mac ios android
   2. 不同浏览器，chrome, safari, edge, firefox
   3. 不同百度版本
   4. 移动端和pc端，看看布局是否适配屏幕大小
4. 安全性测试
   1. 敏感、隐私内容禁止搜索
   2. sql注入，xss攻击等
5. 用户体验测试
   1. 测试搜索框是否支持快捷键，eg 回车键直接搜索
   2. 测试输入错误检查，eg 'shanghi' 能否只能纠错为'上海'
   3. 如果有语音搜索功能，测试语音输入的识别准确率，比如普通话、带口音的输入是否都能识别
6. 界面UI测试
   1. 无错别字
   2. 界面布局合理、颜色搭配合理

### 微信抢红包

1. 功能测试
   1. 正常业务流程
      1. **发送红包**：确认用户能够成功发送红包给指定的联系人或群组
      2. **抢红包**：在红包有效期内，用户点击抢红包的通知消息，正常抢到红包金额
      3. **查看红包记录**：检查用户是否能够方便地查看历史红包记录，包括发送和接收的记录
      4. 时间限制：发一个定时红包，看看时间到了是否提示“已过期”
      5. 定向红包：发一个专属红包，看看其他人领取的时候是否提示“仅限某人领取”
   2. 异常情况测试用例
      1. 发送无效红包：测试用户发送**无效金额**(超过200或者小于0)的红包时是否会得到适当的错误提示
      2. **重复抢红包**：确认用户不能重复抢同一个红包
      3. **超时抢红包**：验证用户在红包有效期过期后是否无法继续抢红包
      4. **异常网络情况下的抢红包**：模拟网络不稳定或断开连接的情况下，确认用户是否能够正常抢红包并显示适当的错误提示
   3. 边界情况测试用例
      1. **金额边界**：尝试发送0.01元（最低金额）和200元（单次上限）的红包，检查系统是否正常处理
      2. **超额测试**：输入超过200元的金额（如201元），验证是否提示金额超限
2. 性能测试
   1. 多人并发同时抢一个：模拟50个用户同时抢一个10人份的红包，检查响应时间是否在1秒内，金额分配是否准确
   2. 弱网环境：在2G网络下抢红包，验证是否能成功领取，或者是否有超时提示
3. 兼容性测试
   1. 不同版本的微信客户端: ios, android, 平板（分辨率等）
4. 安全性
   1. **红包金额保密性**：确认用户在抢红包时是否能够保证其他人无法预先知道红包金额
   2. **防止作弊测试**：模拟作弊行为，如恶意抢红包、利用漏洞等，验证系统是否能够及时检测并采取相应的防护措施
   3. **非法输入**：在红包金额输入框注入SQL语句（如“' OR '1'='1”）或脚本（如`<script>alert(1)</script>`），检查是否被拦截或无异常响应。
5. 界面ui
   1. 错别字、布局清晰、操作直观

### 登录界面测试

1. 功能测试
   1. **正常登录**：输入正确的用户名和密码（如手机号+密码），点击登录，验证是否能成功进入主界面
   2. **错误提示**：输入错误密码，验证是否提示“密码错误”；输入未注册的账号，检查是否提示“账号不存在”
   3. **多方式登录**：测试其他登录方式（如验证码登录、微信扫码登录），确认每种方式都能正常跳转并认证成功
   4. **记住密码**：勾选“记住密码”选项，关闭应用后重启，检查用户名和密码是否自动填充
   6. **密码可见性**：点击密码框的“眼睛”图标，确认密码是否从“••••”切换为明文显示
2. 边界测试
   1. **输入长度**：输入超长用户名（如50个字符）或密码（如32个字符），检查系统是否限制长度或报错
   2. **特殊字符**：输入包含特殊字符的密码（如“p@ss#123”），验证是否能正常识别；输入SQL注入语句（如“' OR '1'='1”），确认是否发生sql注入（不能发生）
3. 性能测试
   1. **响应时间**：在正常网络下输入正确账号密码，点击登录，检查响应时间是否在2秒内
   2. **高并发**：模拟1000个用户同时登录，检查系统是否崩溃或返回“服务器忙”提示
   3. 弱网环境：模拟2G或断网状态登录，验证是否提示“网络异常”或能正常排队重试
4. 安全性测试
   1. SQL注入：在用户名或密码框输入“admin'--”或“1=1”，验证是否会被恶意执行，还是返回错误提示。
   2. XSS攻击：输入`<script>alert('hack')</script>`，检查是否被过滤，而不是执行脚本。
   3. 密码加密：**抓包检查登录请求**，确认密码是否以明文传输，还是经过加密（如HTTPS+MD5）

## 实践

* 测试工具
  * 接口测试工具: postman, apifox
  * 性能测试工具: jmeter
  * 自动化测试工具：
    * selenium: 自动化web应用程序测试, chrome, edge...
    * appium:：自动化移动应用程序测试，ios, android...
  * 单元测试：
    * Pytest: 用于python程序的测试框架
    * JUint: 用于java程序的单元测试框架
  * 抓包工具：Fiddler, charles
