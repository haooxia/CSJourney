# 操作系统笔记

[toc]

![picture 1](../images/a9573c3f86d03cf6ea420352d15615eed47fdddbda60bb0d16c630eaabc1a19d.png)  

## 一、概述

1. 开机：CPU -> 执行BIOS内的“很小的自举装入程序“ -> 找到引导块并装入内存 -> 执行引导块中的“完整的自举装入程序” -> 读入FAT表的块 -> 读入根目录的块 -> 然后就可以创建文件或者运行程序了。

2. 计算机系统（Computer System）自下而上分为：硬件（hardware）操作系统（Operating System）应用程序（application）用户（User）

3. 操作系统的主要功能是什么？
   1. 处理机管理（processor management）（包括进程控制、进程同步、进程通信、调度）
   2. 存储器管理（Memory）（内存分配（静态/动态/连续/非连续分配）、地址映射（逻辑地址-->物理地址）、内存扩充（虚拟存储技术））
   3. 设备管理（device）（缓冲管理、设备分配、设备处理（启动设备、中断设备））
   4. 文件管理（file）（文件存储空间管理、目录管理、文件读/写保护

4. 操作系统的特征（characteristic）

   1. 并发 concurrence：可以在同一时间间隔处理多个进程，需要硬件支持（并发会产生一种并行的错觉）
   2. 共享 sharing：资源可被多个并发执行的进程使用
   3. 虚拟 virtual：将物理实体映射成为多个虚拟设备
   4. 异步Asynchronism：[æˈsɪŋkrəˌnɪzəm] 进程执行走走停停，每次进程执行速度可能不同，但OS需保证进程每次执行结果相同

5. **OS/Computer developing process**

   1. 无操作系统（人工操作方式）：用户独占、CPU等待人工；
      1. **1940s** ENIAC 逻辑门：真空电子管 存储器采用延迟线(delay lines) IO采用打孔纸带
      2. 能跑起来程序已经很牛逼了，程序直接使用指令操作硬件，无需画蛇添足的程序进行管理
   2. 单道批处理：内存只保存一道作业，多用户排队共享计算机
      1. **1950s** 逻辑门：晶体管；内存：磁芯；IO速度严重比cpu慢，中断机制诞生；Fortran诞生
      2. 批处理系统 = 程序自动切换（换卡片/程序）+ 提供库函数API
   3. 多道批处理：同时将多个程序载入内存，且可以灵活调度
      1. **1960s** 出现集成电路、总线；内存更大更快 -> 可以同时载入多个程序到内存，而无需换卡了；更丰富的IO设备；现代os诞生: Multics(MIT1965)
      2. 有了process的概念；丰富了进程管理的API
      3. 进程执行IO时，可以将cpu让给另一进程
         1. 虚拟存储使得多个进程之间进行地址隔离，防止一个程序的bug干掉整个系统
      4. 基于中断机制（eg时钟中断），os的调度策略进行程序定时切换
   4. **1970s** 基本具备了现在能干的所有事情：CISC指令集, PC, IO, 中断, 异常, 网络, PASCAL(1970), C(1972), Apple...
      1. UNIX(1969): 管道 grep socket procfs
         1. BSD(1977) GNU(1983) MacOS(1984) Windows(1985) Linux(1991) Debian(1996) Ubuntu(2004) iOS(2007) Android(2008) win10(2015)
            - > Linux is a kernel of OS, while GNU/Linux(Linux kernel + GNU project) is the whole OS.
            - > GNU include GCC(GNU Compiler Collection, for C), shell(Bash), etc, but do not have a kernel.
   5. **今天**的os：空前复杂, cpu, memory, io device, 应用需求更复杂
   6. ~~分时：及时接收、及时处理，交互性~~
   7. ~~实时：实时控制、实时信息处理~~

6. 特权指令Privileged instructions：IO指令、置中断指令 ----核心态（管态、内核态）kernel mode（操作系统在控制CPU）
   非特权指令：访管trap指令----用户态（目态） User mode（普通应用控制CPU）
7. 中断Interruption过程：关中断--保存断点--引出中断服务程序----保存现场--开中断--执行中断服务程序--关中断--恢复现场--开中断--中断返回

8. 系统调用：
   1. 运行在用户态的程序向os请求需要更高权限运行的服务，系统调用提供用户程序和os之间的接口。
   2. 系统调用由os核心提供，运行在核心态，而普通函数的调用由函数库或用户自己提供，运行在用户态。
   3. 凡是与资源有关的操作都必须通过系统调用方式向os提出请求。

## OS结构

![picture 1](../images/d5f5b0a7839c767e5215761c356e8ae4ca79130c58da848515255c7d1ed852b4.png)  

1. 内核：计算机是由各种外部硬件设备组成的，比如内存、cpu、硬盘等，如果每个应用都要和这些硬件设备对接通信协议，那这样太累了，所以这个中间人就由内核来负责，让内核作为应用连接硬件设备的桥梁，应用程序只需关心与内核交互，不用关心硬件的细节。
2. 内核的基本能力：
   1. 进程调度：管理进程、线程，决定哪个进程、线程使用 CPU；
   2. 内存管理：决定内存的分配和回收；
   3. 硬件通信：管理硬件设备，为进程与硬件设备之间提供通信能力；
   4. 提供系统调用：如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。
3. 内核空间vs.用户空间
   1. 内核空间：只给内核程序访问；用户空间：专门给应用程序访问；
   2. 用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间；
   3. 当进程/线程运行在内核空间时就处于内核态，而进程/线程运行在用户空间时则处于用户态。
   4. 应用程序要进入内核空间，需要通过系统调用：当应用程序使用系统调用时，会产生一个中断。发生中断后，CPU会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把CPU执行权限交回给用户程序，回到用户态继续工作。
4. Linux内核设计理念：
   1. MultiTasK
      1. 并发concurrency：对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观⻆度看，一段时间内执行了多个任务。（虽然任务看起来是同时执行的，但实际上是通过快速地在任务之间切换来实现的，每个任务在任意时刻只能执行一部分）（**并发会产生一种在并行的错觉**）
      2. 并行parallelism：对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行。
      3. ![picture 2](../images/59f72a2b37c44b6c36164e49476be2f47ce704277769a3f9699cb9190706443f.png)  

   2. 宏内核：宏内核的特征是系统内核的所有模块，比如进程调度、内存管理、文件系统、设备驱动等，都运行在内核态。（Linux）
      1. 微内核架构的内核只保留最基本的能力，比如进程调度、虚拟机内存、中断等，把一些应用放到了用户空间，比如驱动程序、文件系统等。（稳定、可靠；但频繁切换到内核态，损耗性能；eg鸿蒙）
   3. ELF 可执行文件链接格式
   4. SMP 对称多处理
5. windows内核
   1. multiTask
   2. SMP 对称多处理
   3. 混合型内核
   4. PE 可移植执行文件：扩展名.exe, .dll, .sys；所以windows和linux的可执行文件不能互相运行

## 二、进程管理

### （一）进程与调度

first of all: code只是存储在硬盘里的静态文件，编译后会生成二进制可执行文件，当我们运行该可执行文件，它会被装在到内存，接着cpu执行程序内的每一条指令，此时，这个运行中的程序，我们称之为process。

1. 进程(实体)组成：程序段program segment；数据段data segment；进程控制块process control block PCB
2. PCB：用来描述进程的数据结构，是进程存在的唯一标识。
   1. PCB组成：
      1. 进程描述信息(pid, uid)
      2. 进程控制信息(进程状态, 优先级)
      3. 资源分配清单内 (内存地址空间，虚拟地址空间，文件列表，io设备信息)
      4. CPU相关信息 (cpu内寄存器的值)
   2. PCB是如何组织的?
      1. 将相同状态的进程PCB通过**链表**连接在一起形成“队列”，比如就绪队列、阻塞队列；（这里的“队列”不是queue，不遵循FIFO，应该就是单链表）
3. . **进程的五种状态**：创建态new；就绪态ready；运行态running；阻塞态blocked；终止态exit
   1. ![picture 3](../images/1995251a5e78bd1eeb1af273747d0b05c61cb6e011ac7d701473ad05ed0f42fa.png)
   2. 运行态->结束态：当进程已经运行完成或出错时，会被操作系统作结束状态处理；
   3. 其实还有一个挂起状态suspend，挂起状态不释放cpu，是一种主动行为; 阻塞状态释放cpu，被动行为; 分为两种：
      1. 阻塞挂起状态：进程在外存并等待某个事件的出现；
      2. 就绪挂起状态：进程在外存，但只要进入内存，即刻立刻运行；
   4. 进程各状态的控制：见p152 xiaolincoding
4. CPU上下文切换是：把前一个任务的CPU上下文（CPU寄存器和PC）存到系统内核，然后加载新任务的上下文到这些寄存器和PC上，然后跳转到PC所指的新位置，执行新任务。根据任务的不同，可以分为进程上下文切换、线程上下文切换和中断上下文切换。
5. 进程上下文切换：各进程之间是共享CPU的，在不同的时候进程之间需要切换，让不同的进程可以在CPU执行，那么一个进程切换到另一个进程运行，称为进程的上下文切换。(进程切换发生在内核态)
   1. 保存处理机上下文，包括PC和其他CPU寄存器
   2. 更新PCB信息（什么意思？？）
   3. 把进程的PCB移动到相应的队列，如就绪队列。
   4. 选择另一个进程执行，并更新其PCB。
   5. 更新内存管理的数据结构
   6. 回复处理机上下文

7. 线程Thread：同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立 的寄存器和栈，这样可以确保线程的控制流是相对独立的。
   1. ![picture 4](../images/d3ed96fe3359fb3428d4bb1410f506baafd12c51c7149689306990abc63d1503.png)
   2. 线程控制块TCB：包括PC，栈指针，寄存器；用户级TCB由线程库函数维护，内核级TCB由os内核维护。

8. **进程和线程的区别？**
   线程被称作轻量级进程，在进程中包含线程。进程有独立的内存空间，不同进程间不能直接共享其他进程资源，同一个进程内的线程共享进程内存空间；相比进程，线程切换对系统开销更小一些；进程是资源分配的最小单位，线程是程序执行的最小单位.
   > 操作系统的任务调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。

   1. 调度。线程是CPU调度的基本单位。
   2. 资源。进程是资源分配的基本单位，线程不独立拥有资源，但可以访问隶属进程的资源。
   3. 并发性。引入线程就是为了获得更好的并发性。
   4. 开销。进程的创建、撤销和切换都要有资源的分配和回收，开销远大于线程的切换。
   5. 地址空间和其它资源。进程的地址空间都是独立的，而线程可以共享隶属进程的地址空间和资源。
   6. 通信方面。进程之间通信需要用进程通信手段实现，而线程间通信可以直接读写数据段。
   ![picture 5](../images/d74ae90cae1b9a61adad408ababfead36f9467fdd7ff0279b0a4d13c5c624646.png)  

9. 线程的上下文切换：
   1. 当进程只有一个线程时，可以认为进程就等于线程； 
   2. 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；
   3. 另外线程也有自己的私有数据，比如栈和寄存器。
   4. 所以现成的上下文切换：
      1. 如果两个线程不属于同一进程，那切换过程等同于进程上下文切换。
      2. 如果属于同一进程，由于虚拟内存是共享的，所以只需要切换线程的私有数据、寄存器等不共享的数据。故而线程的上下文切换开销比较小。
10. 线程间的同步与通信类型有哪些？
    1. 互斥锁mutex；
    2. 条件变量；
    3. 信号量机制

11. 线程的实现方式有哪几种？
    1. 内核级线程kernel thread：在内核中实现的线程（由os内核管理）
       1. 在一个进程中，如果某内核线程发起系统调用而阻塞，不影响其他内核线程的运行。
       2. 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大。
    2. 用户级线程user thread：在用户空间实现的线程
        1. 由用户态的线程库实现和管理，整个线程管理和调度，os内核是不直接参与的。无需用户态和内核态的切换，速度快。
        2. 一个线程发起了系统调用而阻塞，那进程中所包含的用户线程都不能执行了。
    3. 轻量级进程light weight process：内核支持的用户线程，

12. 管程是什么？
   由一组数据及对这组数据操作的定义组成的模块。同一时间只能有一个进程使用管程，即管程是互斥使用的，进程释放管程后需唤醒申请管程资源的等待队列上的进程。进程只有通过进入管程并使用管程内部的操作才能访问其中数据

13. 处理机的三级调度：
   1. 高级调度（作业调度）：把作业从外存中取出，给它分配内存和其它资源，让它称为一个进程，是其能具备竞争处理机的条件。它是主存和辅存之间的调度。
   2. 中级调度（内存调度）：作用是提高内存利用率。将那些不能运行的进程挂起到外存，如果他们已经具备运行条件，有稍微有些空闲，由中级调度决定外存上的进程重新调入内存，并修改为就绪态。
   3. 进程调度（进程调度）：是操作系统最基本的调度。按照某种方法从就绪队列中选取一个进程，将处理机分配给它。频率最高。

14. 不能进行进程调度和切换：中断；原子操作；进程在内核临界区。

15. **处理机/CPU调度**dispatch/scheduling方法：
    - 先来先服务（First Come First Served, FCFS）(非抢占式)：对长作业有利，适合cpu繁忙型作业的系统，不适合io繁忙型作业的系统。
    - 短作业优先（Shortest Job First, SJF）:对长作业不利
    - 高响应比优先（Highest Response Ratio Next, HRRN）:权衡了长作业和短作业
      - $响应比优先权=\dfrac{等待时间+要求服务时间}{要求服务时间}$
    - 时间片轮转（Round Robin, RR）：最古老、最简单、最公平、适用范围最广的算法。(假设所有进程同等重要)
      - 如果时间片设置过短，那么就会造成大量的上下文切换，增大了系统开销。
      - 如果过⻓，就退化成 FCFS 算法了。
    - 最高优先级调度（Highest Priority First, HPF）：从就绪队列选择优先级最高的进程。
    - 多级反馈队列（Multilevel Feedback Queue）：是RR和HPF的综合和发展
      - 「多级」表示有多个队列，每个队列优先级从高到低，同时**优先级越高时间片越短**。
      - 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

16. **页面置换算法？**
    最佳置换算法OPT 先进先出置换算法FIFO 最近最久未使用算法LRU
    时钟算法LOCK 改进型时钟算法

17. **磁盘调度算法？**
    先来先服务FCFS 最短寻道时间优先SSTF 扫描算法SCAN 循环扫描算法C-SCAN

18. **面向过程与面向对象的区别：（问题保留）**
    面向过程让计算机有步骤地顺序做一件事，是过程化思维，使用面线过程语言开发大型项目，软件复用和维护存在很大问题，模块之间的耦合严重。面向对象相对面向过程更适合解决较大的问题，可以拆解问题复杂度，对现实事物进行抽象并映射为开发对象，更接近人的思维。
\
    举例：大象装进冰箱。

    面向过程：打开冰箱 --> 存储大象 --> 关上冰箱
    对于面向过程思想，强调的是过程（动作）.语言：C。

    面向对象：冰箱打开-->冰箱存储大象 -->冰箱关上

    对于面向对象思想，强调的是对象（实体）。语言：C++、Java、C#
    特点：1. 面向对象就是一种常见的思想，符合人们的思考习惯。
    1. 面向对象的出现，将复杂的问题简单化。
    2. 面向对象的出现，让曾经在过程中的执行者，变成了对象的指挥者。

### 进程间通信

每个**进程的用户地址空间都是独立**的，一般而言是不能互相访问的，但**内核空间是每个进程都共享**的，所以进程之间要通信**必须通过内核**。

1. 管道pipeline：linux中的|就是管道，将前一个命令的输出作为后一个命令的输入，单向（半双工），如果需要双向通信需要创建两个管道；
   1. **管道就是内核里面的一串缓存**。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。
   2. |是匿名管道，用完了就销毁了；匿名管道的通信范围是存在父子关系的进程。（因为匿名管道没有实体文件，只能通过fork来复制父进程的文件描述符fd）详见p187
   3. 还有一种命名管道(FIFO)，`makefifo mypipe` ->`echo "helle" > mypipe` -> `cat mypipe`
      1. 命名管道的读取和写入操作都是阻塞的。如果没有数据可读，读取进程将被阻塞，直到有数据可用
      2. 命名管道可以在不相关的进程建通信，因为他有fd可以随意使用；
2. 消息队列：用于解决管道不适合进程间频繁交换数据（通信效率低）的问题；消息队列是保存在内核中的消息链表；
   1. 消息队列不适合比较大数据的传输；
   2. 消息队列通信过程中，**存在用户态与内核态之间的数据拷⻉开销**，因为进程写入数据到内核中的消息队列时，会发生从用户态拷⻉数据到内核态的过程，反之亦然。
3. 共享内存：解决了消息队列切换状态的问题。TODO
4. 进程通信的方式
   1. 低级通信方式：PV操作（信号量机制）。
      1. P：wait(S)原语，申请S资源
      2. V：signal(S)原语，释放S资源
   2. 高级通信方式：以较高效率传输大量数据的通信方式
      1. 共享存储（使用共享空间）
      2. 消息传递（进程间以格式化的消息进行数据交换，底层通过发送消息和接收消息两个原语实现）
      3. 管道通信（两个进程中间存在一个特殊的管道文件，特点：半双工通信）

### （二）同步与死锁

1. 临界资源critical resource：There is only one process using it.such as printer，various.

2. 对临界资源访问过程：进入区（entry section）临界区（critical ）退出区（exit）剩余区（remainder）

3. 同步Synchronism：直接制约关系，两个进程在时间上有先后关系。

   互斥mutual exclusion / mutex：间接制约关系，当一个进程进入临界区，另一个必须等待。

4. **同步的四个准则**：

   1. 空闲让进：If the critical section is free, another process is allowed to enter the critical section.
   2. 忙则等待：If the critical section is busy, other processes must wait.
   3. 让权等待：When a process cannot enter a critical section, the processor should be freed.
   4. 有限等待：Every processor should be able to access the critical section in a limited time.

5. 实现临界区互斥的基本方法：单标志法、双标志先检查、双标志后检查、皮特森算法。硬件方法（中断屏蔽和TSL指令）。信号量法。

6. 管程monitor：是由一组数据及定义在这组数据上的对数据的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程。

   管程的组成：局部于管程的数据，对数据结构的操作，对局部于管程的数据设置的初始化语句。（class）

7. **死锁deadlock**：多个进程因竞争资源而造成的一种僵局，没有外力作用，都无法继续执行。

   原因：对互斥资源分配不当；进程推进顺序不当。

8. 死锁的四个必要条件：互斥条件(Mutual exclusion) 请求与保持条件(Hold and wait) 非剥夺条件(No pre-emption) 循环等待条件(Circular wait)

9. 处理产生死锁的办法有哪些？

   1. 预防死锁（破坏产生死锁的必要条件）
   2. 避免死锁（银行家算法）；
   3. 检测死锁（资源分配图）；
   4. 解除死锁（剥夺资源 or 撤销进程）.

10. 死锁deadlock与饥饿hunger的区别？
    1. 都是资源分配问题
    2. 死锁是等待永远不会释放的资源，而饥饿申请的资源会被释放，只是永远不会分配给自己
    3. 一旦产生死锁，则死锁进程必然是多个，而饥饿进程可以只有一个
    4. 饥饿的进程可能处于就绪状态，而死锁进程一定是阻塞进程

## 三、内存管理

### （一）基础：将多个进程保存到内存中

1. 内存管理memory management功能：内存空间的分配与回收、地址转换（eg VA->PA）、扩充内存空间（虚拟存储技术逻辑上扩充）、存储保护（利用界地址寄存器保护os不受用户进程影响）。

2. **C语言运行过程/源程序->目标程序**：

   源程序(hello.c )->可执行文件(hello)
   1. 预处理阶段（预处理器cpp）：对#开头的命令进行处理，eg #include <stdio.h>将.h文件插入程序。输出文件hello.i;
   2. 编译阶段（编译器ccl）：**翻译**生成汇编语言源程序hello.s；
   3. 汇编阶段（汇编器as）：将hello.s**翻译**成机器指令，打包成一个可重定位目标文件hello.o；**目标文件都从0开始编址，都是独立的逻辑地址/相对地址**
   4. 链接阶段（链接器ld）：将多个目标文件和所需库函数**打包**为一个可执行目标文件hello.exe；**可执行模块具备完整的逻辑地址**
   5. 装入：由装入程序把exe文件装入内存运行；**将逻辑地址转为物理地址（地址重定位），装入到实际的物理地址**

3. 内存保护的方式：

   1. 上下限寄存器法：存放用户作业在主存中的上下限地址。
   2. 重定位寄存器（基址寄存器）和界地址寄存器（限长寄存器）组合法。
      1. 界地址寄存器含有逻辑地址的最大地址，是用来“比较”的；重定位寄存器含有物理地址最小值，是用来“加”的。

4. 逻辑地址virtual 与 物理地址physical：

   1. **逻辑地址（虚地址/相对地址/人的视角）**：编译后每个目标模块都从0开始编制，叫做相对地址或逻辑地址。

   2. **物理地址（实地址/机器视角）**：是地址转换后的最终地址。装入程序将代码装入内存，必须将逻辑地址变成物理地址，称为**地址重定位**。
      1. os如何管理VA和PA之间的关系？内存分段和内存分页。

---

1. 有哪些**连续**分配内存管理方式？

   1. 单一连续分配：将内存分成系统区（低地址）和用户区。优点：简单、无外部碎片；缺点：适用于**单道程序**（整个用户只存放一道程序），有**内部碎片**，内存利用率非常低。
      1. 内部碎片：**已分配**给某进程的内存空间大于该进程实际需要的空间。
      2. 外部碎片：内存中已分配的分区外的存储空间越来越多的碎片难以利用。一般都是进程退出后留下的小块空闲块。
   2. 固定分区分配：将内存空间划分成大小固定的分区，每个分区只装入一个作业。分区大小可以相等也可以不等。优点：可以多道程序; 缺点:分区固定不变，程序不能太大，否则放不进去，有**内部碎片**；内存利用率低。
   3. 动态分区分配：不预先划分分区，而是等进程装入内存时再动态建立分区。优点是：可以使分区大小刚好合适。缺点是：会产生较小的**外部碎片**分配不出去。
      1. 动态分区分配的四种算法：
         1. 首次适应 first fit：空闲分区按地址递增链接。
         2. 最佳适应 best fit：空闲分区按容量递增链接。
         3. 最坏适应 worst fit：按容量递减。会留下很多外部碎片。
         4. 邻近适应 next fit：从首次适应基础上，在上次查找结束位置继续查找。

2. **非连续**分配管理：将一个程序分散地装入不相邻的内存分区（当然需要额外空间存储各区域的索引作为代价）
   1. 按照分区大小是否固定分为：分页存储管理方式和分段存储管理。
   2. 分页存储管理方式根据作业时是否把作业的所有页面都装如内存才可运行分为：基本分页 + 请求分页。
3. 页式内存管理中的**页表**是什么，多级页表呢？
   1. 页表：进程页号 -> 物理内存块号（mapping）
      1. 页表项 = 进程页号 + **内存物理块号**
         1. 所以页表项中的内存物理块号 + 逻辑地址中的页内偏移量共同组成物理地址；
      2. 一个进程对应一张页表。

4. 描述**页式存储管理**。
    1. 把主存空间物理上划分为大小相等且固定的块（页框/页帧）；与固定分区相似，不会产生外部碎片，但这里的块相比于分区要小得多。只有在为进程最后一个不完整的页申请主存块的时候才会产生大概半个块的内部碎片，洒洒水啦。
    2. 每个进程逻辑上以块（页/页面）为单位划分，在执行时以块为单位申请主存中的块空间。
    3. 逻辑地址Logical address = 进程页号 + **页内偏移量**；(地址结构决定了虚拟内存的寻址空间大小)
    4. 进程的页映射到物理内存的块

   逻辑地址 -> 物理地址(核心在于**先找到页表项PA**，然后concat(表项的物理块号, LA的页内偏移量)即可)：
   1. 根据页面大小L，计算出逻辑地址LA的页号(LA/L)和页内偏移量(LA%L)。
   2. 由逻辑地址中的页号与PTR中的页表长度对比，若大，则越界，发生中断。
      1. 页表寄存器PTR中存放页表内存始址 + 页表长度（页表项个数）
   3. 若页号合法：页表项地址 = 页表始址 + 页号 * 页表项长度（页表项(页地址)占用存储空间）。
   4. 物理地址PA = 页表项中块号 + 逻辑地址中的偏移量。
5.  介绍一下快表TLB：
    1. 由于页式存储管理在地址变换时，需要两次内存访问：访问页表（确定所需要的数据或者指令的PA）+ 取数据/指令；故设置快表TLB，充当页表的cache，一个专门的高速缓冲存储器。与之相对的主存中的页表称作慢表。
    2. 引入TLB的地址变换：
       1. 首先将页号与快表的所有页号进行比较，如果命中，直接取出物理块号。即可与LA的页内偏移量形成PA；（仅一次访存）
       2. 若未命中，还是去访问主存中的页表，**同时将其存入快表**。
          1. 一般快表命中率可达90%；又是局部性原理咯。
6.  介绍多级页表：
    1. 当逻辑地址空间很大时，页表长度会大大增加。需要一块比较大的连续物理空间存储，这不好。
    2. 二级页表时 逻辑地址 = 一级页号 + 二级页号 + 页内偏移量
    3. 缺点就是增加了一次访存时间。
7.  描述**段式存储管理**。
    1. LA = 段号 + OFF
    2. 段表项 = 段号(**不占空间(why)**) + 段长 + 本段在主存中始址
    这种管理方式考虑到了程序员的感受，以满足方便编程、信息保护和共享、动态增长及动态链接等要求。它按用户进程中的自然段划分逻辑空间，每个段从0开始编址，并分配连续的地址空间。段内连续，段之间可以不连续。

    逻辑地址->物理地址（与页式类似）
    - 段表项地址 = 段表起始地址 + 段号 × 段表项长度
    - 物理地址 PA = 页表项中本段起始地址 + LA中段内偏移量

### （二）虚拟内存管理

5. 为什么需要VA？如果仅使用PA会怎样？
   1. 当执行多个进程时，完事儿释放的时候，释放空间不连续，出现外部内存碎片无法利用。（连续分配中的动态分区分配）
   2. 多个程序同时执行，他们可以访问相同的内存，可能会相互冲突。

1. **虚拟存储器**：基于局部性原理，将程序的一部分装入内存，而将其与部分留在外存，就可以启动运行程序。在执行过程中，程序要访问的信息不在内存，由操作系统将所需的部分调入内存执行。操作系统将暂时不用的内容换出到外存上，空闲空间存放从外存换入的信息。这样操作系统就**好像**为用户提供了一个比实际内存大得多的存储器。
   1. 之所以叫做虚拟存储器：是因为os提供了部分装入、请求调用和置换功能后，给用户的感觉好像是存在一个比实际物理内存大得多的存储器。
   2. 虚拟存储器的大小由计算机的地址结构决定，而非内存和外存的求和。

2. 虚拟存储技术所需硬件支持：页表机制、缺页中断机构、地址变换机构、一定容量的内存和外存。
3. 地址变换机构：先查块表，若命中直接形成PA，否则 -> 查慢表，若命中形成PA，否则 -> 发生中断，请求调页。
4. 页面置换算法Page replacement algorithm：
   1. 最佳置换算法 optimal replacement algorithm：被淘汰页面是之后最长时间不访问的页面。**理想**情况。
   2. 先进先出置换算法 FIFO：会产生belady异常
      1. Belady异常：分配物理块数增大，缺页次数不减反增。
   3. 最近最久未使用 least recently used（LRU）：最近没用，未来用的概率不大。
   4. 时钟置换算法clock：

5. 驻留集resident set：分配给进程的物理页框数。

6. 工作集working set：某时间间隔内，进程要访问的页面集合。

7. 抖动/颠簸page jitter：刚刚换出的页面又要换入主存。

## 四、文件管理

1. 文件控制块FCB：存放控制文件的信息。FCB的集合就是文件目录。
2. 文件的逻辑结构：
   1. 无结构文件（流式文件）：eg 源程序文件 目标代码文件
   2. 有结构文件（记录式文件）：顺序文件、索引文件、索引顺序文件

3. 硬链接和软链接方式的比较
   1. 硬链接：（基于索引节点的共享方式）这种共享方式中，文件的物理地址和其它的文件属性不再放入目录项中，而是放在索引结点中。在文件目录中只设置文件名和指向索引结点的指针。索引结点中有计数器表示指向这个索引结点的用户目录项的个数。当删除时将索引结点的计数器减一，然后删除对应的用户目录项。当计数器为零时，就将文件彻底删除。
      1. 优点：实现了异名共享。
      2. 缺点：文件拥有者不可删除正在共享的文件。
   2. 软连接：（利用符号链实现文件共享）只有文件的拥有者才拥有只想起索引节点的指针，而共享该文件的其他用户只有该文件的路径名。
      1. 优点：拥有者可删除
      2. 缺点：其他用户开销大

4. 文件的分配方式（对非空闲磁盘块的管理）

   1. 连续分配：FCB中记录起始块号和数量（长度），支持随机访问。
   2. 链接分配：离散分配，消除了外部碎片，提高了利用率。隐式连接分配每个块都有next指针，显式链接分配把 指向各物理块的指针 显式地存在文件分配表FAT中。
   3. 索引分配：索引表，FCB中包括索引块的地址。支持随机访问。(多层索引与混合索引）

5. 对空闲磁盘块的管理
   空闲表法、空闲链表法、位示图法和成组链接法

6. 一次磁盘读写时间 = 寻道时间（磁盘调度算法） + 逆转延迟时间（交替编号、错位命名） + 传输时间

7. 磁盘调度算法：

   1. FCFS：公平
   2. 最短寻找时间优先算法（Shortest Seek Time First,SSTF）：眼前最优未必总体最优，“饥饿”现象
   3. SCAN算法/电梯算法：磁头移动到最外侧磁道才往内移动。利于端头一侧。
   4. CSCAN：规定磁头单向移动，使个位置磁道的响应频率平均。

## 五、IO系统

1. 四种IO控制方式：
   1. 直接控制方式/程序查询方式。CPU每读取一个字，就要对外设状态进行轮询检查。CPU和IO只能串行工作，cpu利用率低。  由于CPU的高速性和IO设备的低速性，致使CPU大部分时间都处于等到IO设备的循环，造成CPU资源的极大浪费。
   2. 中断驱动方式。CPU在向IO设备发出读命令后，可以转去做其它的事情，等到IO设备数据就绪，由IO设备主动发出中断请求打断CPU。这样是CPU和设备都可以尽量忙起来。
   3. DMA方式。DMA方式基本思想是，在主存和IO设备之间直接开辟数据通路，彻底解放CPU。其特点是基本单位是数据块，所传送的数据是从设备直接送入内存的。仅仅在一个或多个数据块传输开始或结束时才需要CPU的干预，这个数据块的传输是在DMA控制器的控制下完成的。
   4. 通道控制方式。IO通道是指专门负责输入输出的处理机。它可以进一步减少CPU的干预。
2. IO系统层次结构：用户层io软件 -> 设备独立层软件 -> 设备驱动程序 -> 中断处理程序 -> 硬件
3. 假脱机技术 SPOOLing技术：为了缓和cpu的高速性和io设备低速性之间的矛盾，该技术利用专门的外围控制机，将低速IO设备的数据传送到高速磁盘上或者相反。**SPOOLing技术将一台物理I/O设备虚拟为多台逻辑I/O设备。**
   特点：提高了IO的速度，将独占设备改造成共享设备，实现了虚拟设备的功能。结构：输入井和输出井、输入缓冲区和输出缓冲区、输入进程和输出进程。
