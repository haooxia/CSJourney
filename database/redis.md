# Redis八股

- [Redis八股](#redis八股)
  - [基础](#基础)
    - [什么是Redis](#什么是redis)
    - [redis可以用来做什么](#redis可以用来做什么)
    - [为何要用Redis作为MySQL的缓存](#为何要用redis作为mysql的缓存)
  - [Redis数据结构](#redis数据结构)
    - [简单动态字符串SDS](#简单动态字符串sds)
    - [整数集合IntSet](#整数集合intset)
    - [Dict](#dict)
      - [Dict扩容与缩容 (include rehash)](#dict扩容与缩容-include-rehash)
    - [ZipList](#ziplist)
    - [Redis数据结构及使用场景](#redis数据结构及使用场景)
    - [实现方式](#实现方式)
    - [Zset的底层实现](#zset的底层实现)
  - [Redis线程模型/网络模型](#redis线程模型网络模型)
    - [Redis为什么快](#redis为什么快)
    - [Redis是单线程还是多线程](#redis是单线程还是多线程)
    - [redis哪些地方使用了多线程](#redis哪些地方使用了多线程)
    - [redis网络模型](#redis网络模型)
  - [缓存](#缓存)
    - [数据库与缓存的一致性](#数据库与缓存的一致性)
    - [缓存穿透](#缓存穿透)
      - [详解布隆过滤器](#详解布隆过滤器)
    - [缓存雪崩](#缓存雪崩)
    - [缓存击穿 / 热点key问题](#缓存击穿--热点key问题)


## 基础

### 什么是Redis

Redis: Remote Dictionary Service

* Redis是一种基于键值对(key-value)的**NoSQL**数据库，对数据的读写操作都是在**内存**中完成，因此读写速度非常快，常用于**缓存cache**，**消息队列mq**、**分布式锁**等场景
  * redis可以将内存数据持久化到磁盘上，并不会断电丢失
* Redis提供了多种数据类型来支持不同的业务场景，并且**对数据类型的操作都是原子性**的，因为执行命令由单线程负责的，**不存在并发竞争的问题**
* Redis还支持**事务、持久化、Lua脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制**等等。

### redis可以用来做什么

1. **缓存**：由于所有数据都存在内存中，读写速度远超基于磁盘存储的数据库(mysql)，所以使用redis作为缓存可以极大地提高应用的响应速度和吞吐量
2. **分布式锁**：Redis可以实现分布式锁，用来控制跨多个进程或服务器的资源访问
3. **消息队列**：充当简单的消息队列，依赖发布/订阅模式(Pub/Sub)
4. **排行榜**/计数器：Redis的ZSet非常适合用来实现排行榜的功能，同时Redis的原子递增操作可以用来实现计数器功能

### 为何要用Redis作为MySQL的缓存

源于：**高性能**和**高并发**两种特性

* 高性能：首次通过mysql从磁盘读取，很慢，缓存到redis后相当于直接操作内存，很快
* 高并发：单台设备的**Redis的QPS(Query Per Second)是mysql的10倍**，**redis单机的QPS可轻松突破10w，而mysql单机QPS很难超过1w**；故而直接访问redis可承受的请求远超过mysql；顺便可以很好地降低后端的负载

但缓存存在一定的成本：

* 数据一致性成本
* 代码复杂度上升
* 集群维护成本上升

![picture 10](../images/88a07ce85d74b61fee28c9bd4143f1e21ee2b43234e9ff6155c54d9b9f91f0ef.png){width=80%}

## Redis数据结构

### 简单动态字符串SDS

* 众所周知：**Redis中保存的Key是字符串，value往往是字符串或者字符串的集合**
* redis没用C语言自带的字符串/字符数组，因为它有很多问题：
  * 获取字符串长度的需要通过运算；size()-1或遍历
  * 非二进制安全；你不能存`\0`
  * 不可修改

![picture 12](../images/6bd00c2e6ba2a80e60ac84d3a71f7cfabf32b3f9e662fa51dc1735b3214ec7ab.png)
![picture 13](../images/c49edbbb094148d6a7c1c9dfa1c62f9366e20b161896fbb6c1b9e5696f8fe056.png)

> "申请内存"这个动作很消耗资源，故而预分配内存

### 整数集合IntSet

IntSet是Redis中set集合的一种实现方式，基于**C语言整数数组**来实现，并且具备长度可变、有序等特征。

Intset可以看做是特殊的整数数组，具备一些特点：

* Redis会确保Intset中的元素唯一、有序
  * 唯一性：就是查找一下看看有没有，有则不添加
  * 有序性：也是二分找到待插入位置
* 具备**编码升级**机制，节省内存空间
* 底层采用**二分查找**方式来查询

![picture 14](../images/8e64ee67435a6c172d96edb8689e2b4f56543f60945484a95fa86940e421480f.png)  

IntSet编码会自动升级（如果你开始用的int16，当你插入了一个16表示不了的数字，就会触发升级）：

* 升级编码为int32，并按新的编码方式及元素个数扩容数组
* **倒序**依次将数组中的元素拷贝到扩容后的正确位置
* 将待添加的元素放入数组末尾

### Dict

Redis是一个键值型的数据库，我们可以根据键实现快速的增删改查。而键与值的映射关系正是通过Dict来实现的。

底层就是**拉链法**（看起来和老版HashMap基本差不多）**数组+单链表**
![picture 17](../images/8a9ec1cc5b9db82743d3b88913768457b755d4b3230ad309532fef78f04c315b.png)  
 
> **size的值永远是2的n次方**，如此才能保证size-1的**低二进制位刚好全是1**，如此`hash % size == hash & (size - 1) == hash & sizemask`

哈希冲突时是头插到链表，因为比较方便，尾插你还得遍历过去，麻烦

#### Dict扩容与缩容 (include rehash)

* Dict是数组+单链表，当集合中元素较多时，必然导致哈希冲突增多，**链表过长**，则查询效率会大大降低。
* Dict在**每次新增键值对**时都会检查负载因子（LoadFactor = **used/size**） ，满足以下两种情况时会触发**哈希表扩容**（**每次翻倍**）：
  * 哈希表的LoadFactor >= 1，并且服务器没有执行BGSAVE或者BGREWRITEAOF等**后台进程** (说明cpu比较闲)；
  * 哈希表的LoadFactor > 5（忍不了了）
* 每次删除键值对时会检查负载因子，当`LoadFactor < 0.1`时会进行**哈希表收缩**
* 扩容与收缩时都会创建一个新的哈希表`ht[1]`，即有新的size，那你想要迁移到新哈希表，原来的元素位置肯定得重新计算了（注意迁移过程中旧哈希表`ht[0]`也是可以用的奥），此即**rehash过程**；而且我们不能一次性rehash，不然数据量很大的时候，主进程阻塞严重，此即**渐进式rehash**：
  * 计算新size，并申请内存，创建dictht，并赋值给`dict.ht[1]`
  * 设置`rehashidx=0`，标示开始rehash；(-1表示无需)
  * ~~**开始rehash，一次性将`dickt.ht[0]`中的每一个数据都rehash到`dict.ht[1]`**~~
  * 每次执行增删改查时，都检查一下`rehashidx`是否`>-1`，如果是，就把该`rehashidx`的entry进行rehash到`ht[1]`，并`rehashidx++`，即**每次CRUD就rehash一个元素**，挺妙的
    * **中间如果有人过来查询，修改或删除，需要同时到新旧两个dictht中查找，先找`ht[0]`旧的**
    * **新增的话就直接插入到新dictht就完事儿 `ie, ht[1]`**
    * 这样**可以确保旧的`ht[0]`元素只减不增**
  * 将最后的`ht[1]`赋值给`ht[0]`，并将`ht[1]`初始化为空哈希表，释放原来的旧的`ht[0]`的内存

### ZipList

### Redis数据结构及使用场景

* 常见的有五种数据类型
  * String类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等
  * List类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。
  * Hash类型：缓存对象、购物车等。
  * Set类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
  * 有序集合Zset类型：排序场景，比如排行榜、电话和姓名排序等。
* 新版本新增四种
  * 位图BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等
  * HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
  * 地理空间GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
  * 消息队列Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。

![picture 4](../images/b8d6ec9aa02b299d1cb9740d1c661e91488b27ba826975f10ef661b1a231f8fe.png)  

### 实现方式

暂略

### Zset的底层实现

Zset的底层数据结构是由 **压缩列表 或 跳表** 实现
如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 类型的底层数据结构；
如果有序集合的元素不满足上面的条件，Redis会使用跳表作为Zset类型的底层数据结构；

## Redis线程模型/网络模型

> 请先复习`os_essence.md`中Linux的5中IO模型

### Redis为什么快

单线程的reids吞吐量10w/s

之所以redis核心是单线程还这么快的原因：

* 纯内存操作
* 避免多线程切换和线程安全
* IO多路复用

### Redis是单线程还是多线程

如果说的是Redis的核心业务部分(命令部分)，答：单线程（即使是最新的redis
如果聊整个Redis，答：多线程

**redis为何坚持使用单线程？**

* redis是**纯内存操作**（抛开持久化不谈），执行速度很快，他的性能瓶颈是**网络延迟或内存**而非**CPU**，因此多线程不会带来巨大的性能提升
  * IO多路复用的提升相比于纯内存并不多
* 多线程会导致过多的**上下文切换**(线程数超过核数)，带来不必要的开销
* 线程**安全**问题，必然要引入线程锁这种安全手段，复杂度增高，性能降低，还不兼容
* redis采用**IO多路复用**机制处理大量的客户端socket请求，实现一个线程处理多个并发的IO操作

### redis哪些地方使用了多线程

* Redis单线程指的是==接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端这个过程是由一个线程（主线程）来完成的==

* 但Redis程序并不是单线程的，Redis在启动的时候，是会**启动后台线程**（BIO）的：包括一个**关闭文件线程、AOF刷盘线程和一个lazyfree线程异步释放内存**(比如删除大key的`unlink key`)
  * 因为这几个任务挺耗时的，交给主线程来干的话，容易阻塞
* reids6.0采用多个IO线程处理网络请求，来解决网络IO的瓶颈

### redis网络模型

redis使用epoll()实现IO多路复用，多个客户端连接服务端时，Redis会将客户端socket的fd注册进epoll红黑树，然后epoll同时监听多个fd，如果有数据来了就通知事件处理器赶紧处理，这样就不会存在**服务端一直等待某个客户端给数据**的情形

6.0之前redis的IO多路复用模式使用的是**单Reactor单线程模式**
6.0之后将网络IO部分改成了多线程

## 缓存

### 数据库与缓存的一致性

当我们将数据缓存到redis之后，如果修改了数据库，肯定要同时给缓存数据改了，不然不乱套了...此即缓存更新策略

缓存更新策略：

* **内存淘汰**：啥也不干，开摆；利用redis自己的内存淘汰策略：内存不足时自动淘汰部分数据，下次再查询就可以更新了（很牵强...一致性很差；eg LRU, LFU算法
* **超时剔除**：给缓存数据设置TTL，到期后自动删除缓存，下次查询时更新缓存（一致性一般般..修改数据库后直到ttl到期前都不一致
  * 作为兜底方案
* ==**主动更新**==：自己写业务逻辑，更新数据库时同时更新缓存（一致性很好，但累啊
  * Read/Write Through(读穿/写穿)策略：将缓存和数据库整合为一个服务,由该服务来维护一致性。应用程序只需要与这个服务交互,无需关心缓存一致性问题。（就直接依赖别人的服务，透明
  * Write-Back / Write-Behind 写回策略：调用者**只操作缓存**, 由其他线程异步地将缓存数据**定期**持久化到数据库, 保证最终一致性。但缓存变了到写回之前依然不一致；此外如果此时redis宕机了就寄了
  * ==**Cache Aside/旁路缓存策略(唯一神)**==：由缓存的调用者，在更新数据库的**同时**更新缓存
    * 写策略：==**先**更新数据库，再**删除**缓存==


综上所述，缓存更新策略最佳实践：

* 对于低一致性需求：使用Redis自带的内存淘汰机制即可。比如店铺**类型**的缓存，很久不会变咯
* 对于高一致性需求：主动更新 + 超时剔除兜底
  * 读操作：先查缓存，命中直接返回，未命中再去查数据库，并写入缓存，**设置ttl**
  * 写操作：先更新数据库，再删除缓存；还要保证原子性

### 缓存穿透

**缓存穿透**问题：客户端请求的数据在缓存和数据库中都不存在，导致每次查询都会绕过缓存直接打到数据库，对数据库造成巨大压力（攻击数据库的好办法）；即**大量无效请求直接打到数据库**
> Cache Penetration 其实翻译为'渗透'挺好（不怀好意者通过这个漏洞避开redis渗透到mysql

应对方案：

* 主动方案（不让被穿透）/ 限制非法请求
  * 增加id的复杂度，避免被猜出来id规律
  * 增加id格式校验(比如删除0，删除范围外的值)
  * 增强用户权限校验
* 被动方案（穿透了再去弥补）
  * **缓存空对象**（简单粗暴
    * 消耗额外内存（我编各种各样的id打给你，你都得存着，但也可以通过ttl(2min)解决，但还是有点难受，项目中采用bloom filter
    * **可能造成短期的不一致**：我们在缓存了null之后，此时我们真的给数据库插入了要请求的新数据，但redis还是会返回null，走不到数据库 -> 只能控制ttl来缓解了，或者你数据库新增数据时去redis覆盖一下 
  * **Bloom布隆过滤**

**如何使用bloom filter解决缓存穿透问题？**

我们提前将所有可能存在的合法数据进行映射，并将其加入布隆过滤器。查询redis缓存和数据库之前，先通过布隆过滤器检查请求的元素是否存在：

1. 如果bloom大哥说不存在，则**一定不存在**，直接拒绝，避免访问redis缓存和mysql数据库
2. 如果bloom大哥说存在，则**大概率存在**，继续查询缓存和数据库；
   1. 如果缓存和数据库都没找到的话，则还是发生缓存穿透，此时我们再去**缓存空对象**来防止短时间内的重复穿透

#### 详解布隆过滤器

[reference](https://javaguide.cn/cs-basics/data-structure/bloom-filter.html)

布隆过滤器(Bloom Filter)**用于快速判断一个元素是否在集合中**；
是Bloom老哥1970年提出的一个**数据结构**，由**二进制位数组 + 一系列哈希函数**组成；

特点：**相比于我们用的HashMap，空间占用小很多，效率高很多**：100w个元素只需要100w bit ≈ 122KB空间!
缺陷：具有**一定的错误识别率**，难以删除，集合中元素越多，哈希冲突的概率越高，误报的可能性越大

**布隆过滤器若说某个元素存在，小概率会误判（因为哈希冲突的存在），若说某个元素不在，那么该元素一定不在。**

---

**原理**：

![picture 11](../images/919df8d02ae5fac3370885d0c0d09f1d5b9fa792bbadfe69b500a10c39f59a39.png)  
> 初始时bloom filter均为0

当一个元素加入bloom filter时，进行如下操作：

* 使用多个哈希函数对元素值进行哈希计算得到**多个哈希值**
* 根据得到的哈希值，在位数组中把对应下标的值**置为1**（可能取余%啥的

当我们需要判断一个元素是否存在于bloom filter时，进行如下操作：

* 对给定元素再次进行**相同的哈希计算**
* 判断哈希值对应下标的元素值**是否都为1**，是则说明这个值在布隆过滤器中，如果**存在一个值不为1**，说明该元素不在布隆过滤器中。

由于不同元素可能算出相同的hashcode，故布隆过滤器说某元素存在，小概率会误判；我们可以增加数组容量或调整哈希函数来减少误判。

> 手撕[bloom filter](https://javaguide.cn/cs-basics/data-structure/bloom-filter.html#%E7%BC%96%E7%A0%81%E5%AE%9E%E6%88%98) (不难)

---

使用场景：

* **判断给定数据是否存在**
  * 防止缓存穿透
  * 判断一个数字是否存在于包含大量数字的数字集中（数字集很大，上亿）
  * 垃圾邮件过滤（判断一个邮件地址是否在垃圾邮件列表中）
  * 黑名单功能（判断一个IP地址或手机号码是否在黑名单中）
* **去重**
  * 对巨量的订单号/手机号/QQ号去重

### 缓存雪崩

同一时段**大量的缓存key同时失效(TTL同时到期)**或**Redis服务器宕机**，导致大量请求打到数据库，可能给数据库干崩溃，引起整个系统都崩了

解决方案：

* 大量的缓存key同时失效
  * **均匀设置过期时间**（给不同的Key的TTL添加随机值
* Redis服务器宕机
  * **构建Redis缓存高可用集群**：通过主从节点的方式构建Redis缓存高可靠集群。主节点废了，从节点顶上
  * **牺牲部分服务**
    * **服务熔断机制**：暂停业务应用对缓存服务的访问，直接返回错误，不用再继续访问数据库（全部请求都无法工作
    * **请求限流机制**：只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到Redis恢复正常并把缓存预热完后，再解除限流
  * 多级缓存：浏览器缓存 -> nginx缓存 -> redis缓存...

### 缓存击穿 / 热点key问题

指缓存中**某个热点key过期的瞬间**，大量并发请求直接打到数据库，干废数据库

条件：**高并发访问 && 缓存重建业务较复杂**
> 缓存重建是指缓存过期之后的重建，有的key重建过程是要从多个表查询和运算，可能达到数百ms，这段时间内都无法命中

![picture 8](../images/fc1345f209763180b6352d88494853e34d968a88e11444aae61978f2112c36d8.png){width=80%}

解决方案：

* **互斥锁**：只让一个线程拿了互斥锁去重建缓存，其他未能获取互斥锁的请求，等待锁释放后重新读取缓存（那也太难顶了
  * 互斥锁选择了**一致性Consistency**，但很慢，**可用性Availability**很低(CAP理论)
  * 实现简单；但性能低，有死锁风险
* **逻辑过期**：不给热点数据设置TTL，也就不会失效；但要额外设置一个过期时间字段，当真的过期了，得创建线程去重建缓存，重建过程中其他请求直接拿这个过期了的旧数据
  * 逻辑过期选择了**可用性**，但不保证**一致性**
  * 
