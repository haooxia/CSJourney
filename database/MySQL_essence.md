# MySQL

- [MySQL](#mysql)
  - [基础](#基础)
    - [SQL vs. NoSQL](#sql-vs-nosql)
      - [ACID vs. BASE](#acid-vs-base)
    - [数据库的三大范式](#数据库的三大范式)
    - [char vs. varchar](#char-vs-varchar)
    - [关键字 in vs. exists](#关键字-in-vs-exists)
    - [常用函数](#常用函数)
    - [一条select语句是如何执行的 ☆](#一条select语句是如何执行的-)
    - [讲讲mysql的存储引擎](#讲讲mysql的存储引擎)
      - [InnoDB vs. MyISAM](#innodb-vs-myisam)
    - [MySQL一行记录是怎么存储的 (额外信息 + 真实数据)](#mysql一行记录是怎么存储的-额外信息--真实数据)
      - [记录的额外信息](#记录的额外信息)
      - [记录的真实数据](#记录的真实数据)
  - [索引](#索引)
    - [索引是什么 有什么优缺点 ☆](#索引是什么-有什么优缺点-)
      - [按物理存储分类](#按物理存储分类)
      - [按数据结构分类](#按数据结构分类)
        - [为什么MySQL InnoDB选择B+tree作为索引的数据结构？ ☆](#为什么mysql-innodb选择btree作为索引的数据结构-)
      - [从字段特特性分类](#从字段特特性分类)
      - [按字段个数分类](#按字段个数分类)
        - [联合索引使用原则](#联合索引使用原则)
    - [索引下推优化 (Index Condition Pushdown)](#索引下推优化-index-condition-pushdown)
    - [什么时候需要创建索引 ☆](#什么时候需要创建索引-)
    - [什么时候不需要创建索引 ☆](#什么时候不需要创建索引-)
    - [什么时候索引失效 ☆](#什么时候索引失效-)
    - [有什么优化索引的方法](#有什么优化索引的方法)
  - [事务](#事务)
    - [事务的四大特性 ACID ☆](#事务的四大特性-acid-)
      - [InnoDB引擎通过什么技术保证这四个特性的？](#innodb引擎通过什么技术保证这四个特性的)
    - [并行(发)事务会引发什么问题 ☆](#并行发事务会引发什么问题-)
    - [事务隔离级别 ☆](#事务隔离级别-)
      - [事务隔离级别是如何实现的](#事务隔离级别是如何实现的)
    - [MySQL是如何解决并发问题的](#mysql是如何解决并发问题的)
    - [MVCC实现原理](#mvcc实现原理)
      - [什么是版本链](#什么是版本链)
      - [什么是readview](#什么是readview)
      - [版本链数据访问规则](#版本链数据访问规则)
  - [锁](#锁)
    - [锁分类](#锁分类)
      - [InnoDB行级锁的实现](#innodb行级锁的实现)
      - [乐观锁 vs. 悲观锁](#乐观锁-vs-悲观锁)
  - [日志](#日志)
    - [日志文件分为几种](#日志文件分为几种)
    - [为何需要undo log](#为何需要undo-log)
      - [实现事务回滚, 保障事务原子性](#实现事务回滚-保障事务原子性)
      - [实现MVCC的关键因素](#实现mvcc的关键因素)
    - [BufferPool](#bufferpool)
    - [有了undolog为啥还需要redolog](#有了undolog为啥还需要redolog)
      - [undo log vs. redo log](#undo-log-vs-redo-log)
      - [为何需要binlog](#为何需要binlog)
        - [binlog vs. redolog](#binlog-vs-redolog)
      - [两阶段提交](#两阶段提交)
  - [SQL优化](#sql优化)
    - [慢SQL](#慢sql)
      - [如何定位慢SQL](#如何定位慢sql)
    - [explain执行计划](#explain执行计划)
    - [有哪些优化SQL的方式](#有哪些优化sql的方式)
  - [架构](#架构)
    - [基于binlog实现主从复制](#基于binlog实现主从复制)
    - [分库和分表是什么](#分库和分表是什么)

TODO: https://xiaolincoding.com/interview/mysql.html#sql%E5%9F%BA%E7%A1%80
* 读写分离
* 一条update语句是如何执行的（各种log看看，xiaolin
* sql优化（join

MySQL核心：

* 索引（聚簇, 非聚簇, B+ Tree, 最左匹配）
* 事务（MVCC, ReadView, 隔离级别, 间隙锁）
* 日志（undo, redo, binlog）

## 基础

### SQL vs. NoSQL

SQL(structured query language): 关系型数据库, 存储结构化数据, 这些数据逻辑上以行列二维表的形式存在，每一列代表数据的一种属性，每一行代表一个数据实体, eg SQL Server, Oracle, MySQL, PostgreSQL

NoSQL (Non-SQL): 非关系型数据库, 存储方式可以是JSON文档、哈希表或者其他方式, eg Redis, MongoDB

#### ACID vs. BASE

**选择SQL还是NoSQL?**

关系型数据库支持ACID (原子性，一致性，隔离性和持续性)。相对而言，NoSQL采用更宽松的模型BASE， 即基本可用(Basically Available)，软状态(Soft stat)和最终一致性(Eventual Consistency)
> BASE详见`microService.md`

* 选择哪种模型取决于应用的具体需求。**ACID适合需要严格数据一致性的场景**，而**BASE则适合需要高可用性和扩展性的场景**。
  * **NoSQL数据之间无关系，所以很容易扩展**，比如redis自带主从复制模式、哨兵模式、切片集群模式
  * 相反关系型数据库的数据之间存在关联性，水平扩展较难，需要解决跨服务器JOIN，分布式事务等问题
* 比如银行应用就必须保证ACID，否则一笔钱可能被使用两次；又比如社交软件不必保证ACID，因为一条状态的更新对于所有用户读取先后时间有数秒不同并不影响使用。

### 数据库的三大范式

<!-- 数据库的三大范式是用于设计**关系型**数据库的规范，旨在**减少数据冗余，提高数据一致性和避免数据异常** -->

* 第一范式 (1NF) ：**数据库表的每一列都是不可分割的原子数据项**
  * eg 用户地址应该拆分成省、市、区、详细信息4个字段
* 第二范式 (2NF): 在满足1NF的条件下，**确保表格的每一列(非主键列)都和主键相关，而不能只与主键的某一部分相关**（主要针对**联合主键**而言）
  * ![picture 20](../images/8813bd821657f8247d7973b82a12dbf1262a7cd777fc009860bc5d7bfeb51d68.png){width=80%}
  * 所以需要分为俩表格
* 第三范式 (3NF): 满足1NF和2NF条件下，**确保表格每一列(非主键列)直接依赖主键，不应依赖于其他非主键列**
  * ![picture 21](../images/5a65b4c303ca5c77c4f8b57a0aade48c5b9149b043150766934c80e6c286f22f.png){width=80%}

> 实际开发过程中，三大范式有时候反而成为了老太婆的裹脚布，让表的设计变得复杂而又啰嗦

### char vs. varchar

* char: 固定长度字符串，定义时需指定固定长度，**存储时会在末尾补足空格**。适合存储长度固定的数据，对于短字符串效率较高
  * 因为长度固定，所以存取速度要比varchar快很多，甚至能快50%，但会占据多余的空间，空间换时间
  * 最多能存放255个字符，和编码无关
* varchar: 可变长度字符串，定义时需要指定**最大长度**，**实际存储时根据实际长度占用存储空间**。适合存储长度可变的数据，节约存储空间
  * 存取慢，不占据多余的空间，时间换空间
  * 最多能存放65532个字符

### 关键字 in vs. exists

IN和EXISTS都是用来处理子查询的关键词

* in用于检查左边的表达式**是否存在于**右边的**列表**或**子查询的结果集**中。返回true/false
* exists用于**判断子查询是否至少能返回一行数据**。它不关心子查询返回什么数据，**只关心是否有结果**。如果子查询有结果，返回TRUE

区别与选择：

* **性能差异**：在很多情况下，EXISTS的性能优于IN，特别是**当子查询的表很大时**。这是因为**EXISTS一旦找到匹配项就会立即停止查询，而IN可能会扫描整个子查询结果集**
* **使用场景**：**如果子查询结果集较小且不频繁变动，IN可能更直观易懂**。而当子查询涉及外部查询的每一行判断，并且子查询的效率较高时，EXISTS更为合适

### 常用函数

* 字符串函数
  * concat(s1,s2)
  * length(s)
  * lower(s), upper(s)
  * trim(s): 去掉头尾的空格
  * substring(s, start, len)
* 数值函数
  * ceil(x), floor(x)
  * rand(): return random value in 0-1
  * round(x,y): 四舍五入 y位小数
  * abs(x)
* 日期函数
  * curdate(): 返回date
  * curtime()
  * now(): 返回date和time
  * year(date), month(date), day(date)
  * datediff(date1, date2)
* 聚合函数
  * count(column): 计算指定列的非null值个数
  * sum(column), avg(c), max(c), min(c)

### 一条select语句是如何执行的 ☆

`select * from product where id = 1;`

![picture 1](../images/6cc5dd44fe8864c1d271f72732a4f845ed12aacef6e07b1d6f40ad5c7b13ae1f.png){width=80%}

MySQL架构可分：Server层和存储引擎层两部分

* Server层：负责**建立连接、分析和执行SQL**。MySQL大多数的核心功能模块都在这实现
* 存储引擎层：负责**数据的存储和提取**。支持 InnoDB、MyISAM、Memory等多个存储引擎，**不同存储引擎共用一个Server层**。MySQL5.5开始，InnoDB成为了MySQL的默认存储引擎
  * 存储引擎层既包括位于内存中的BufferPool，又涉及到位于磁盘上的实际数据

---

1. **连接器**：负责和客户端建立连接、权限验证(验证用户名和密码)、维持和管理连接
   1. mysql基于TCP，需要三次握手，客户端通过ip+port(3306)来连接mysql服务器：`mysql -h $ip -u $user -p`
2. **查询缓存**：mysql拿到一个查询select请求后，会先到查询缓存(query cache)看看是否执行过这条语句，命中的话直接返回结果。之前执行过的select语句及其结果会以key-value的形式缓存在**内存**中，key为SQL查询语句，value为查询结果。
   1. > 所谓transformer的key value query来源
   2. 但其实查询缓存很**鸡肋**，命中率很低，mysql8.0之后**删掉**了查询缓存。
3. **解析器**：你输入的是字符串+空格组成的sql，mysql需要识别出里面的字符串分别是什么，代表什么；**词法分析**会识别出字符串中的关键字(eg, select, from...)；**语法分析**会判断sql语句是否满足mysql语法
4. **预处理器**：检查表和字段是否存在，以及将`select *`中的`*`扩展为表上的所有列(ok 有点像C语言的预处理指令)
5. **优化器**：基于查询成本的考虑，选择查询成本最小的**执行方案**；比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。或者在一个语句中有多表关联(join)时，决定各表的连接顺序
   1. > 通过explain命令查询SQL语句的执行计划
6. **执行器**：根据执行计划执行SQL查询语句，从存储引擎读取记录，返回给客户端

### 讲讲mysql的存储引擎

* InnoDB：MySQL的默认存储引擎，提供了**对事务ACID的支持**、**行级锁、外键约束**等特性。它适用于高并发的读写操作，支持较好的数据完整性和并发控制
* MyISAM：老默认存储引擎，具有**较低的存储空间和内存消耗**。MyISAM**不支持事务、行级锁和外键约束**，因此在并发写入和数据完整性方面有一定的限制
* Memory：将数据**存储在内存中**，适用于对性能要求较高的读操作，但是在服务器重启或崩溃时数据会丢失。它也不支持事务、行级锁和外键约束

#### InnoDB vs. MyISAM

> 早期mysql用的是MyISAM，现改为InnoDB

* **事务**：InnoDB支持事务，符合ACID特性，MyISAM不支持事务
* **锁粒度**：InnoDB最小的锁粒度是**行锁**，并发性能更高，MyISAM最小的锁粒度是**表锁**
* **外键支持**：MyISAM不支持外键
* **索引结构**：InnoDB采用聚集索引，数据和索引存在一起，主键索引的叶子节点包含数据行，查询效率高；MyISAM采用非聚集索引，**数据和索引分开存储**，叶子结点仅保存数据文件的指针，需要额外的查找
* **表的行数**：InnoDB不保存表的具体行数，执行`select count(*) from table`时需要全表扫描。**MyISAM保存表的行数**，执行上述语句时只需要读出该变量即可直接返回，速度**很快**

### MySQL一行记录是怎么存储的 (额外信息 + 真实数据)

> first: 记录是按照row行存储在磁盘中的，数据库的读取是按照page页为单位读取的(不然总不能每读一行一次磁盘io吧，和分页存储原理一致)，一页16KB，即一次**最少**从磁盘读取16KB内容到内存，或者**最少**把16KB刷新到磁盘。
> > 基本单位是页，但没说一次只能读取一页奥...

![picture 4](../images/9835a08d8ece53b0fa6b664205c1edf29a572f419433b6efd7a09f0d5fe4a287.png)  

#### 记录的额外信息

* **变长字段长度列表**：存储变长字段(eg varchar类型字段)的实际数据**长度**
* **NULL值列表**：每一个允许为NULL的列对应着一个bit，1表示该列为null，0非null
* **记录头信息**
  * **delete_mask**：标识此条数据是否被删除。我们执行detele删除记录的时候，并不会真正的删除记录，只是将这个记录的delete_mask标记为1
  * **next_record**：下一条记录的位置。记录与记录之间是通过链表组织的
  * record_type：当前记录的类型

#### 记录的真实数据

三个隐藏字段：

* row_id: 如果既没有指定主键，又没有唯一约束，那么InnoDB就会为记录添加row_id隐藏字段作为**主键约束**; (非必需，6B)
* trx_id: 表示最近操作该记录的事务id(transaction_id); (必需，6B)
* roll_pointer: 这条记录上一个版本的指针；每次修改某条记录时，都会把旧的版本写入到undolog中，然后这个隐藏列相当于一个指针，可以通过它找到该记录修改前的信息；roll_pointer是必需的，占用7个字节。（见MVCC）

## 索引

### 索引是什么 有什么优缺点 ☆

索引就是数据的目录，帮助存储引擎快速获取数据，空间换时间。

没有索引的话，数据库会进行**全表扫描(Sequential Scan)**，也即必须读取表中每一行数据来查找匹配的行(O(n))，上B+树索引之后是O(log(n))

> eg `select * from user where age = 18;` 全表扫描就是自顶向下逐一扫描age列，B+Tree是我们给age列建立一个B+Tree，然后你搜索18就快的多了 

* 优点
  * 提高查询效率，降低数据库IO成本
  * 提升排序效率
* 缺点（问题不大）
  * 索引占用磁盘存储空间 (数据和索引都存在磁盘文件.idb中)
  * 虽然大大提升了查询效率，但是**降低了增删改的效率**
    * > 因为除了更新数据外还要更新索引嘛，还有索引节点页分裂等问题

---

**总论：**

* 每个表都**必须有且只有**一个**聚集索引**(clustered index), (选取规则：主键-> 第一个唯一(unique)且非空的索引 -> 自动生成一个隐式自增row_id列作为索引键)
* 其他索引都叫做**辅助索引/二级索引**(secondary index)。
* InnoDB所有索引都默认使用B+Tree索引。

==**核心**==：**聚簇索引的叶子结点的值是主键对应的这一整行数据，而辅助索引的叶子节点的值是主键，便于下一次回表查询**。
> 你也可以在辅助索引中添加更多字段来避免回表查询：借助**联合索引**，在索引处加上你需要的字段，注意叶子结点的值仍然是主键，这个是不能更改的。（此即**覆盖索引优化**(参考索引优化方法章节)

比如有这么一张表格：
![picture 0](../images/5780aa80dcba306167b460c5c0ec11682f4baae1ca40e18327dd4eb6ca8d2128.png){width=60%}

![picture 2](../images/455b87f220e3584b0707429f5c2040d273d26b7e1ce728812631bcb69d89dcaa.png)  
如果执行: `select * from product where id = 5;`, 通过主键索引查询id=5的商品信息，会从B+Tree自顶而下查询，先对比5和(1,10,20)，遂进入二层1列，与(1,4,7)对比，遂进入三层二列，然后在叶子结点中继续遍历找到5，即可拿到id=5的员工的所有信息

![picture 3](../images/4d1a2d8548840fac82807efd61d3998039d04523e59dbef8dd1504f834426e9e.png)  

如果执行: `select * from product where product_no = 0002`, 通过二级索引查询商品信息，类似地，一路对比非叶子找到叶子结点，然后**只能拿到主键值**，此时需要**通过主键索引的B+Tree**查询主键值对应的完整用户信息(整行数据)，此过程谓之**回表查询**，即需要查**两个B+Tree**才拿到结果。

但如果你查询: `select id from product where product_no = 0002`, 通过二级索引查用户id，这可以直接从二级索引的叶子拿到结果，就无需回表查询了，此过程谓之**覆盖索引**，即**通过二级B+Tree就能查到结果**。

> 总结：所以查询一般有三种情况：直接走聚集索引B+Tree(根据主键查询)；直接走二级索引B+Tree(覆盖索引)；先走二级索引B+Tree再走聚集索引B+Tree(回表查询)

#### 按物理存储分类

* 聚集索引(主键索引)
* 二级索引(辅助索引)

#### 按数据结构分类

B+树索引：
数据库的**索引和数据都是存储在硬盘**的，所以每次读取一个索引节点需要一次磁盘io。B+Tree相比于B树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘I/O依然维持在3-4次(包括读数据那一次)。
> 一个索引节点对应磁盘中的一个数据页(about 16KB)，意味着上下层索引节点位于两个数据页，意味着需要两次磁盘IO
> 主键索引中索引节点存放的是主键，按递增顺序存放，其他非主键字段索引的索引节点存的就是对应字段的数据，同样按序存放
> 树高为2大概可以存储18000条记录，树高为3大概是2200w条。

* B+树（多路平衡搜索树）特点：
  * 一个节点有多个子节点（多路）-> 所以树比较**矮胖**
  * 非叶子不保存数据，只作为索引；所有key都会出现在叶子中
  * 叶子按照从小到大排序，形成双向链表

B+树中**每个节点都是一个数据页**，只有叶子才存放了数据，非叶子值存放目录项作为索引。

##### 为什么MySQL InnoDB选择B+tree作为索引的数据结构？ ☆

* B+Tree vs. B Tree
  * B+树非叶子只存储索引而B树存索引和数据。所以B+能存储的索引数目也就更多，所以B+树更加**矮胖**，进而磁盘io次数就比较少。
  * B+Tree叶子采用双向链表连接，适合mysql中的**范围查找**，B Tree做不到
  * B+树增删效率更高：**B+树有大量冗余节点**，删除一个节点的时候，**可以直接从叶子节点中删除**，甚至可以不动非叶子节点，删除非常快。B+树的插入也是一样，有冗余节点，插入可能存在节点的分裂（如果节点饱和），但是最多只涉及树的一条路径。B树没有冗余节点，删除节点的时候非常复杂，可能涉及复杂的树的变形。（一言以蔽之：**B+树的分裂与合并相比B树更为简单**
* B+Tree vs. 二叉树
  * n个节点m叉树树高是$O(log_m^n)$，二叉树m=2，B+树一般m>100, 所以显然B+树是更加矮胖的，树高就代表着磁盘io次数。(==索引和数据存在磁盘中==)
* B+Tree vs. Hash表
  * Hash非常适合等值查询(O(1)搜索复杂度)，但并不适合范围查询。
  * 无法利用索引进行排序操作

#### 从字段特特性分类

* **主键索引**：建立在主键字段上的索引，唯一非空，默认创建 (PRIMARY)
* **唯一索引**：建立在unique字段上的索引，唯一，可为null (UNIQUE)
* **普通索引**：建立在普通字段上的索引，可不唯一，可为null
* **前缀索引**：对字符类型字段的前几个前缀字符建立的索引，而不是在整个字段上建立的索引，可以缩小索引占据的磁盘空间，提高查询效率

```sql
-- 创建普通索引
create index index_name on table_name(column_name) 
-- 创建唯一索引
create unique index index_name on table_name(column_name) 
-- 创建全文索引
create fulltext index index_name on table_name(column_name) 
-- 创建前缀索引 (提取前n个字符构建索引)
create index index_name on table_name (column_name(n))
```

#### 按字段个数分类

* 单列索引
* **联合索引**：通过将多个字段组合成一个索引。即在B+树中采用多个字段的值作为key值，比较时**先后比较**多个key。（**前面的key是全局有序的**，后面的key是在前面key相同时才有序，即**局部相对有序**）

```sql
-- 创建联合索引：索引字段(product_no, name)
CREATE INDEX index_product_no_name ON product(product_no, name)
```

> 在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引， 而非单列索引。

![picture 4](../images/2a50237305b2d7827477a4cd803fe9d7d703f0724cfc36122a08091057f316cd.png){width=80%}

![picture 5](../images/b53fbf311a4b62edaea59148c13cf9b9fae773ca2a1c6fe5f983603fb9b69c13.png){width=80%}

---

##### 联合索引使用原则

1.联合索引遵循**最左前缀法则**：查询从索引的最左列开始(必须存在，但未必需要放在第一位)，并且不跳过索引中的字段。

* **如果不从最左列开始，联合索引完全失效**
* 如果从最左开始，但**跳过中间某列，则后面的字段失效**（部分失效）
* 多个字段顺序是可以改变的

2.联合索引**范围查询**中规则：出现范围查询(> or <)，范围查询右侧的列索引失效。
> * 改成>=就行了（如果业务允许的话
> * `>=, <=, between and(>= <=), like(也存在闭区间)`不会停止匹配
> * `select * from t_table where a > 1 and b = 2`: 符合a>1的记录肯定是相邻的(因为先按a排序嘛)，然后找到a>1的所有记录范围之后，b字段的值是无序的，所以不能b=2这个b字段就没用到联合索引
> * `select * from t_table where a >= 1 and b = 2`: 虽然在符合a>=1条件的二级索引记录的范围里，b字段的值是无序的，但是对于符合a=1的二级索引记录的范围里，b字段的值是。所以a=1时b字段可以用到联合索引。
>   * 但不鸡肋吗，大部分情况(>=1)仍然没用

### 索引下推优化 (Index Condition Pushdown)

* 传统索引扫描：在没有ICP的情况下，MySQL存储引擎**使用索引**查找满足索引条件的记录，然后**从表中读取完整的行数据**返回给MySQL Server，MySQL Server **==再对==其他非索引条件进行过滤**。这意味着MySQL可能需要从表中读取大量数据，即使其中有很多不满足查询条件
* 启用 ICP：当ICP被启用时，MySQL存储引擎会**在使用索引扫描数据的同时，尽可能地应用额外的查询条件（非索引条件(即联合索引中索引失效的字段)）(由MySQL Server==下推==给存储引擎的部分条件)**。即在索引扫描阶段，MySQL就可以排除不满足非索引条件的记录，从而减少需要从磁盘中读取的数据量。这种方式减少了不必要的I/O操作，提高了查询效率

![picture 1](../images/1fffbb3b899edaa4b0d44ae2814c899ab4e21c4a18490264d271e522aab775a1.png)  

![picture 2](../images/1abe83c865fdb8554666149dbc8a0efee26d69e1bd5125c7a3aa7b928043a53c.png){width=70%}


### 什么时候需要创建索引 ☆

* **表的主键**：自动建立索引
* **频繁作为查询条件的字段**：经常出现在WHERE子句中的字段，创建索引可加快查询
* **排序和分组字段**：如果查询中经常对某些字段进行排序（ORDER BY）或分组（GROUP BY），为这些字段创建索引可以大大提高排序速度（因为建立索引之后在B+树中的记录已经排好序，查询的时候不用再次排序）
* **查询中与其他表关联的字段**：在多表连接查询中，外键关系的字段应该创建索引，以提高连接查询的效率
<!-- * **大表中的关键列**：在大表中，如果查询的效率变得很低，可以考虑在关键列上创建索引 -->

### 什么时候不需要创建索引 ☆

* **不用于查询条件的字段**：WHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的
* **小表**：对小表创建索引可能会带来额外的开销，因为**在小数据集中扫描整个表可能比使用索引更快**
* **高频更新表**：如果表中数据频繁更新、插入或删除，维护索引会带来额外的开销。这些操作需要额外的资源来保持索引结构的更新和完整。
* **低选择性列 / 重复值较高列**：选择性低的列（即具有大量重复值的列），如性别、布尔值等，使用索引通常无助于性能提升，因为索引**树的深度很浅**，查找效率接近于全表扫描

### 什么时候索引失效 ☆

* 不要在索引列上进行**使用函数**或者**表达式计算**，索引将失效（如substring, length, +1, -1）
  * **因为索引存的是索引字段的原始值**，而非经函数计算后的值，故而.
* **最左前缀法则**：对于联合索引，查询条件必须遵循最左前缀原则。如果查询条件未使用联合索引的最左侧字段，则索引将失效
* **使用LIKE关键字**：模糊匹配中，如果仅仅是尾部模糊匹配，索引不失效，但如果是头部模糊，索引失效(`like %xxx`, `like %xx%`会失效)
  * 因为%代表任意长度的字符串，以%开头时，mysql必须从第一条记录逐个进行匹配，无法利用索引的有序性。而以%结尾时，可以利用索引找到%前面的字符串
* **用or连接条件时，只有两侧都使用索引时才有效，一侧没有就失效**
* **隐式类型转换**：MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过**CAST函数**实现的，等同于对索引列使用了函数，所以就会导致索引失效
* 如果mysql认为使用索引比全表更慢，则不用索引；（受该字段的数据分布影响，很智能）

### 有什么优化索引的方法

* **前缀索引优化**：减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度
* **覆盖索引优化**：覆盖索引是指SQL中 query 的所有字段，在索引B+Tree的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作
  * **实际上是通过联合索引来实现的**，是将你需要的字段放到联合索引内，而非放到叶子结点的值（值只存主键）
* **主键索引最好是自增的**：如果使用自增主键，那么每次插入的新数据就**会按顺序添加**到当前索引节点的位置，**不需要移动已有的数据**，当页面写满，就会自动开辟一个新页面
* **防止索引失效**


## 事务

事务是**一组操作的集合**，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败

```sql
# 手动控制事务方法（显式开启事务）[推荐]
start transaction; -- 开启事务 或者begin
-- 事务操作
commit; -- 提交
rollback; -- 回滚
```

![picture 15](../images/0c12f1a2d63d780ac7c76c8e155ffabdfbf5084cd0db8af9ee3f75186b5bd566.png)  


### 事务的四大特性 ACID ☆

实现事务必需遵守ACID四个特性

* **原子性**（Atomicity`[ˌætəˈmɪsəti]`）：事务是不可分割的最小操作单元，一个事务中的所有操作要么全部完成，要么全部不完成，不会结束在中间某个环节，如出现错误就回滚(undo log)
* **一致性**（Consistency）：一个事务执行之前和执行之后都必须处于一致性状  态。比如a与b账户共有1000块，两人之间转账过程中可能暂时处于不一致状态，但事务提交时必须保证它们的账户总和还是1000
* **隔离性**（Isolation）：允许多个并发的事务同时对数据修改和读取，执行互不干扰，防止多个事务并发执行由于交叉执行造成数据不一致的情况。（隔离级别越高，越安全但也越低效）(MVCC/锁机制)
* **持久性**（Durability`[ˌdjʊərəˈbɪləti]`）：事务一旦提交或回滚，它**对数据库中的数据的改变就是永久**的，确保了即使在系统崩溃或故障的情况下，已提交的事务所做的修改也不会丢失(redo log)
  * 不允许撤回奥，undo log是在事务提交之前存储更新前的数据的，提交后就不能用undo log了

#### InnoDB引擎通过什么技术保证这四个特性的？

* 原子性：undo log (回滚日志)
* 持久性：redo log (重做日志)
* 隔离性：MVCC (多版本并发控制) 或 锁机制
* 一致性：持久性 + 原子性 + 隔离性

### 并行(发)事务会引发什么问题 ☆

多个并发事务同时操作某数据库/表所引发的问题

* **赃读 (dirty read)/问题最严重**：一个事务A读到另一个事务B还**未提交**的数据；如果事务B后来回滚，事务A读到的数据就是无效的脏数据，这可能导致事务A基于不存在的数据做出错误的决策。
* **不可重复读 (non-repeatable read)**：同一事务先后读取同一个数据结果不一致*或被删除了*;
  * 事务A多次读取同一数据，在A读取过程中，事务B修改并提交了该数据
  * update或**delete**引起
* **幻读 (phantom read`[ˈfæntəm]`)**：在同一事务中执行相同的查询时，结果集出现了**原本不存在的数据**；原因是另一事务在查询范围内insert了新纪录
  * 幻读与insert相关，**delete是不可重复读**
  * 即幻读的重点在于新增操作,而不是修改或删除现有数据

区别：

* 脏读涉及未提交的数据
* 不可重复读涉及已提交的数据修改
* 幻读涉及已提交的插入或删除操作

>忽略：所以“不可重复读”和“幻读”都是读的过程中**数据前后不一致**，只是**前者侧重于修改和删除，后者侧重于添加**（数据操作不同）。前者侧重于**单个数据项**，后者侧重于**一批数据**（影响范围不同）。所以可以说严格来讲“幻读”可以被称为“不可重复读”的一种特殊情况。但是从数据库管理的角度来看二者是有区别的。解决“不可重复读”只要加行级锁就可以了。而解决“幻读”则需要加表级锁，或者采用其他更复杂的技术，总之代价要大许多。这是搞数据库的那帮家伙非要把这两者区分开的动机吧。
[reference](https://www.zhihu.com/question/392569386/answer/1434210648)

### 事务隔离级别 ☆

> 事务隔离级别的实现依赖于锁机制和MVCC

由于多个事务并发执行可能出现脏读、不可重复读、幻读的问题，为了解决这些问题，就诞生了隔离级别的概念

* **读未提交RU(Read Uncommitted)**: 一个事务还没提交时，它做出的变更就能被其他事务看到，即引起脏读
  * 可能出现脏读、不可重复读、幻读
* **读已提交RC(Read Committed)**: 一个事务提交之后，该变更才能被其他事务看到
  * 避免了脏读，可能出现不可重复读和幻读
* **可重复读RR(Repeatable Read) (default)**: 确保在同一个事务中多次读取相同记录的结果是一致的，即使其他事务对修改了该条记录，也不影响当前事务
  * 避免了脏读和不可重复读，可能幻读
* **串行化S(Serializable)**: 读操作在数据上加**表级共享锁**，直到事务结束释放；写操作在数据上加**表级排他锁**，直到事务结束释放
  * 解决了所有问题
  * **隔离水平最高，最安全，效率最低(大量的锁竞争以及超时问题)**

#### 事务隔离级别是如何实现的

* 读未提交：因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了，不加任何锁
* 读已提交：通过read view实现，创建readview时机：**在每次读时**生成一个readview，保证每次读操作都是最新的数据
* 可重复读：通过read view实现，创建readview时机：**在启动事务时**生成一个readview，然后**整个事务期间都用这个readview**
* 串行化：加读写锁的方式来避免并行访问

### MySQL是如何解决并发问题的

* **事务隔离级别**：通过设置合适的事务隔离级别，可以在多个事务并发执行时，**控制事务之间的隔离程度**，以避免数据不一致的问题
* **锁机制**：Mysql提供了多种锁机制来保证数据的一致性，包括行级锁、表级锁、页级锁等。通过锁机制，可以在读写操作时对数据进行加锁，**确保同时只有一个操作能够访问或修改数据**
* **MVCC**：通过**保存不同版本的数据来实现不同事务之间的隔离**。在读取数据时，Mysql会根据事务的隔离级别来选择合适的数据版本，从而保证数据的一致性

### MVCC实现原理

**基本原理：**

MVCC即多版本并发控制（Multi-Version Concurrency Control）：**通过保存不同版本的数据来解决数据库并发问题，通过版本链和readview实现的(InnoDB)**

* 传统的锁机制：**当一个事务正在写数据时，其他事务必须等待其完成才能读数据**
* MVCC：允许读操作访问数据的一个旧版本快照，同时写操作创建一个新的版本，这样读写操作就可以并行

> 感觉思想应该还是“修改时copy一份，老版本还可以并发地读”；读写分离思想/CopyOnWrite思想，maybe...

**MVCC关键组件：undo log, 隐藏字段/版本链, readview**
MVCC优势：

* 无锁并发读取：读不用加锁
* 解决读写冲突：读写不会相互阻塞，我们有多版本啊
* 支持多种隔离级别：

#### 什么是版本链

我们之前有说mysql一条记录 = 记录的额外信息 + 记录的真实数据（数据 + row_id + trx_id + roll_ptr）

* **db_trx_id**: 当一个事务改动某记录时，就会把该事务的事务id记录在trx_id隐藏列里
* **db_roll_ptr**: 每次改动某记录时，都会把旧版本的记录写入到undo log中，然后将这个**roll_ptr指针指向每一个旧版本记录**，于是就可以通过它找到修改前的记录

> 这俩隐藏列构成**版本链**

![picture 16](../images/7918b41084db8d1402929df2c3e4e60a6f465a76e1b0d558cd99900d4c4bc416.png){width=70%}

版本链 [image visualization link](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/mysql-765b3d83-14eb-4b56-8940-9d60bfaf1737.jpg)


#### 什么是readview

答：**数据快照**

> readview是实现MVCC的关键组件

readview主要用来处理 读已提交 和 可重复读 隔离级别，为了实现一致性读而创建的数据结构

![picture 8](../images/3f9b4b6ba2f0439a7dee8409173cbec12aa4bcfb533c140e55bd374128c152e3.png){width=60%}
> 可以理解为：横轴上这么多事务id，都是对某一字段的

**当事务开始执行时，InnoDB会为该事务创建一个readview**，这个readview会记录四个重要信息：

* `creator_trx_id`：创建该ReadView的事务id
* `m_ids`：在创建Read View时，数据库中**活跃事务的id列表**，“活跃事务”指开始了但还没提交的事务
* `min_trx_id`：**最小活跃事务id**，表示最早的活跃事务id
* `max_trx_id`：**下一个事务将要使用的id**，即当前最大事务id+1（**事务id是自增的**）

#### 版本链数据访问规则

当一个事务(db_trx_id)去访问某条数据时，InnoDB会根据**readview中的信息**来判断该数据的**某个版本**是否可见：

<!-- * `if trx_id == creator_trx_id`: 说明该版本是当前事务自己创建的，当然可以访问咯   -->
* `if db_trx_id < min_trx_id`: 说明该版本是在创建ReadView前**已经提交**的事务生成的，可以访问
  * 即如果某个数据版本的DB_TRX_ID小于readview的min_trx_id
* `if trx_id >= max_trx_id`: 说明该版本是在当前事务创建之后才开始的，不可访问
* `if (min_trx_id < trx_id < max_trx_id)`: 需要判断trx_id是否在活跃事务列表m_ids列表中，如不在，说明该版本已经提交可以访问。如在，说明该事务还活跃（启动了还没提交），不可访问

## 锁

### 锁分类

![picture 19](../images/9125f3798e1e58922bb2c622760bb92c60894075b5ac7f92355ee8c2340d70ff.png)  

MySQL InnoDB按**锁粒度**可分为：

* **全局锁**：锁定整个数据库的所有表，通常用于**全库逻辑备份**等操作，因为我们想保证备份期间数据不被修改，要能让这个备份可以真实反映这一时刻的真实状态(不然会违背数据一致性 consistency)
  * 通过`flush tables with read lock`会将整个数据库设置为**只读**，这时**其他线程如果增删改(DML)或修改表结构(DDL)都会阻塞**
  * `mysqldump -uroot -pxiahao table_name > tmp.sql;` (逻辑备份即**导出为一些sql语句**(创建表+insert语句))
* **表级锁**：锁粒度大，发生**锁冲突概率高**，**并发度最低**，不会出现死锁；`lock tables`
  * **表锁**：`lock tables name read/write;`
    * 表共享读锁（ie**读锁** read lock）: 读锁会阻塞自己和其他客户端的写，但不阻塞读
    * 表独占写锁（ie**写锁** write lock）: 写锁会阻塞自己和其他客户端的写和读
  * **元数据锁(MDL)**：对数据库表进行操作时，会**自动**给这个表加上元数据锁，是为了保证当用户对表执行**CRUD操作时，防止其他线程对这个表结构做了变更**，即执行DML时会自动阻塞DDL
    * 即为了避免DML(增删改)和DDL(定义语言,修改表结构 eg alter)的冲突
    * **原理**：DML会自动对表加共享MDL，DDL会自动加独占MDL，故而DML之间兼容，和DDL就不兼容了
  * **意向锁**：为了避免执行DML时，加的**行锁与表锁冲突**，故引入意向锁，使得表锁不用检查每行数据是否枷锁，使用意向锁来减少表锁的检查；故线程A对某条行进行CRUD加行锁时(参见后文)，然后**线程A会同时对表加上意向锁**，然后另一线程B加表锁时无需再去遍历了，可直接判断是否可以加锁；
    * 一言以蔽之：加行锁时会顺道加个意向锁，后续加表锁时就可以快速判别了
    * 具体的意向锁也分为意向共享锁和意向排他锁，共享锁和表锁共享锁兼容，和表锁排他锁互斥...
  * ~~**AUTO-INC锁**：用来实现主键自动自增(AUTO_INCREMENT)~~
* **行级锁**：锁定粒度小，发生锁冲突的概率低，**并发度高**
  * InnoDB支持 MyISAM不支持
  * **行锁基于索引**，即对索引上的索引项加锁，而非基于记录；**如果不通过索引字段检索数据**，InnoDB将对表中所有记录加锁，即**升级为表锁**
  * **行级锁分为行锁、间隙锁和临键锁**
<!-- * ~~**页锁**：开销和加锁速度介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般~~ -->

#### InnoDB行级锁的实现

* **Record Lock 记录锁/行锁**：直接锁定某行记录。当我们使用唯一性的索引(包括唯一索引和聚簇索引)进行等值查询且精准匹配到一条记录时，此时就会直接将这条记录锁定。
  * 例如`select * from t where id =6 for update;`就会将id=6的记录锁定
  * ![picture 14](../images/1d7575ff2db171736e8c7ca2af1f09efaa9fc972980f84d3eac47408883374c8.png)
  * 行锁也分为共享锁S和排他锁X
  * **常见CRUD上的行锁**： ![picture 18](../images/dda2a9806ba116ea07626841aff4bbf8e5cb8025e231d3d952c191b23de45127.png)
  * > 默认select不加锁，是快照读
* **Gap Lock 间隙锁**：指的是两个记录之间逻辑上尚未填入数据的**左开右开区间**；
  * **唯一**索引上的等值查询，给不存在的记录加锁时会优化为间隙锁
  * 例如`select * from t where id =3 for update;` 或者`select * from t where id > 1 and id < 6 for update`;就会将(1,6)区间锁定。
  * ![picture 13](../images/5c6bf9d36cbf29b01cf4a40c16f0a1e5e2908ff8c6dcfe03c2f94fd22af4af2b.png)
  * **间隙锁的唯一目的是防止其他事务插入间隙，==避免幻读==**；（**在可重复读事务隔离级别下**）
* **Next-Key Lock 邻键锁**(默认行锁类型)：间隙加上它右边的记录组成的**左开右闭区间**；也即记录锁+间隙锁
  * `select * from t where id between 1 and 10 for update;`
  * **唯一**索引上的范围查询会加临键锁
* ~~**Insert Intention Lock 插入意向锁**~~
<!-- * 一个事务在插入一条记录时需要判断一下插入位置是不是被别的事务加了意向锁，如果有的话，插入操作需要等待，直到拥有gap锁的那个事务提交。但是事务在等待的时候也需要在内存中生成一个锁结构，表明有事务想在某个 间隙 中插入新记录，但是现在在等待。这种类型的锁命名为 Insert Intention Locks ，也就是插入意向锁 。（不同于意向锁）~~ -->


在InnoDB中，**普通的SELECT语句不加锁(属于快照读(MVCC))**。对于使用`FOR UPDATE`或`LOCK IN SHARE MODE`的SELECT语句，InnoDB会**根据查询条件自动加上相应的行级锁**(是否精确匹配到一行，是否范围匹配等)。

#### 乐观锁 vs. 悲观锁

按**加锁机制**/锁的特性划分：

* **乐观锁**：假设冲突是罕见的，不加锁，而是在提交时检查数据是否被其他事务修改。通常通过版本号或时间戳来实现
* **悲观锁**：假设冲突是常见的，主动加锁以防止其他事务修改数据；通常使用`select ... for update`在读数据时加锁，**直到事务提交或回滚时释放**(而非select执行完毕就释放奥)
  * 数据库中的行锁，表锁，读锁，写锁均为悲观锁。

解决超卖问题：

```sql
# 乐观锁
UPDATE inventory SET count = count - 1, version = version + 1
WHERE product_id = 1 AND version = current_version;

# 悲观锁
START TRANSACTION; # 开启事务
SELECT * FROM inventory WHERE product_id = 1 FOR UPDATE; # 加锁
UPDATE inventory SET count = count - 1 WHERE product_id = 1;
COMMIT; # commit时才释放锁，也即锁定了整个事务
```


<!-- ### mysql死锁排查

1. 查看死锁日志 `show engine innodb status;`
2. 找出死锁sql
3. 分析sql加锁情况
4. 模拟死锁案发
5. 分析死锁日志
6. 分析死锁结果 -->

## 日志

### 日志文件分为几种

* **undo log (回滚日志)**，是Innodb存储引擎层生成的日志，实现了事务中的**原子性**，主要**用于事务回滚和MVCC**。
* **redo log (重做日志)**，是Innodb存储引擎层生成的日志，实现了事务中的**持久性**，主要用于**掉电等故障恢复**；
* **bin log (二进制日志/归档日志)**，是Server层生成的日志，主要用于**数据备份和主从复制**；
* **relay log (中继日志)**，用于主从复制场景下，从库slave通过io线程拷贝主库master的bin log后本地生成的日志

### 为何需要undo log

> 执行一条update语句时会涉及到undo log, redo log, bin log三种日志

#### 实现事务回滚, 保障事务原子性

undo log 是一种用于撤销回退的日志，它保证了事务的 ACID 特性中的**原子性（Atomicity**）。

在事务没提交之前，MySQL会先**记录更新前的数据到undo log日志文件**里面，当事务回滚时，可以利用undo log来进行回滚。

![picture 3](../images/2b9e80eb0ac57ed26b752e22032ed86da0deb3b42154fede97c3a8102f1a9fb8.png){width=30%}

每当 InnoDB 引擎对一条记录进行增删改，要**把回滚时需要的信息**都记录到undo log里：

* 在**插入**一条记录时，要把这条**记录的主键值记下来**，这样之后回滚时只需要把这个主键值对应的**记录删掉**就好了
* 在**删除**一条记录时，要把这条**记录中的内容都记下来**，这样之后回滚时再把由这些内容组成的记录**插入**到表中就好了
* 在**更新**一条记录时，要把**被更新的列的旧值记下来**，这样之后回滚时再把这些列**更新为旧值**就好了

#### 实现MVCC的关键因素

undo log还有一个作用，**通过ReadView + undo log实现 MVCC（多版本并发控制）**

### BufferPool

> BufferPool和Query Cache不同：虽然二者都是mysql的缓存机制。Query Cache则缓存解析后的SQL语句及其结果集(位于server层, **没啥用**)。Buffer Pool主要缓存InnoDB存储引擎的表和索引数据页(**位于存储引擎层, 内存中**, 很重要)。

在 MySQL 中，数据存储在磁盘上。当需要更新一条记录时，首先从磁盘读取该记录，然后在内存中进行修改。修改后，**选择将数据缓存起来而不是立即写回磁盘**，这样下次有查询语句或者修改命中了这条记录，直接读取缓存中的记录，就不需要从磁盘获取数据了。


**InnoDB 存储引擎**设计了缓冲池（Buffer Pool）来优化数据库的读写性能：

* 读取数据：如果数据在 Buffer Pool 中，客户端直接从中读取；否则，从磁盘读取。
* 修改数据：如果数据在 Buffer Pool 中，直接**修改该页并将其标记为脏页**（表示内存数据与磁盘数据不一致）。为减少磁盘I/O，**脏页不会立即写入磁盘**，而是由后台线程在合适时机进行写入

### 有了undolog为啥还需要redolog

**BufferPool的数据安全性**：Buffer Pool 提高了 MySQL 的读写效率，但由于它基于内存，存在数据丢失的风险，比如在断电或重启时，未写入磁盘的脏页数据可能会丢失。

解决办法：==**Redo Log + WAL（Write-Ahead Logging）技术**(写前log)==
> A-head B: 在B操作之前，操作A；即write-ahead: 写前（**强调顺序**）
> A-On B: 在操作B时，操作A；eg CopyOnWrite (**强调触发条件**)

1. 更新内存：当需要更新一条记录时，InnoDB 首先在内存中进行修改，并将该页标记为脏页
2. 记录日志：更新操作以Redo Log的形式记录下来，**这时更新操作就算完成了**。Redo Log记录了具体的修改操作，**包括对某个数据页的具体更新位置和内容**(*所谓 物理日志*)
3. 后台刷新：InnoDB会在适当的时候，由后台线程将Buffer Pool中的脏页刷新到磁盘，这就是WAL技术的体现。WAL的核心思想是**先记录日志，再延迟将实际数据写入磁盘**

**事务提交与数据恢复：**

* 事务提交时：在事务提交时，只需将Redo Log持久化到磁盘(当然也有一个redo log buffer, 不是每次都写)，而不必等待脏页数据的持久化。这种机制**使得事务可以快速提交**，提升了数据库的响应速度
* 系统崩溃恢复：如果系统崩溃，**未持久化的脏页数据可能会丢失，但由于Redo Log已经持久化**，MySQL在重启后可以根据Redo Log的内容将所有数据恢复到最新状态

注意本质：redolog和数据都是要写到磁盘的，何必多此一举？
**Redo Log与存入磁盘的实际数据不同**：Redo Log记录的是对单个数据页的具体修改（如某个页的某个偏移量的值被修改为某个值），而实际存入磁盘的数据是完整的数据页。这样，在系统重启或崩溃后，MySQL可以根据Redo Log重建数据，使数据库恢复到崩溃前的状态。
而且，写入**redolog是追加，顺序写**，然后写入数据是**随机写**，顺序写比随机写可高效多了，故开销更小

![picture 4](../images/a23ffe5c8de418900eee382df9ed2cf18a56cb29bc01f4f6f8099f61c9fa58b3.png){width=70%}

#### undo log vs. redo log

redo log 和 undo log 这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：

* redo log 记录了此次事务**完成后**的数据状态，记录的是**更新之后**的值
* undo log 记录了此次事务**开始前**的数据状态，记录的是**更新之前**的值

**事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务**，故而redo log保证了ACID的持久性

#### 为何需要binlog

##### binlog vs. redolog

* 定于/作用不同
  * binlog**记录**对数据库的**逻辑操作**，如增删改等。主要用于**数据恢复、主从复制**。**关注逻辑层面，高层次的数据操作**
  * redo Log：**记录对数据页的物理修改**，确保在系统崩溃时能够恢复未持久化的数据，主要用于**崩溃恢复**。**关注物理层面，具体的页的修改**
* 适用对象不同：
  * binlog 是Server 层实现的日志，所有存储引擎都可以使用
  * redo log 是 Innodb 存储引擎实现的日志
* 文件格式不同：`eg: update student set c = 1 where id = 2`
  * binlog有三种格式，statement(default), row, mixed(混合二者)
    * statement: 记录修改数据的SQL语句（so 逻辑日志）,即直接记录`update stu...`
    * row: 记录行数据最终被修改成什么样了, 记录`id=2的行在更新后的完整数据`
  * redo log是**物理日志**，记录的是在某个数据页做了什么修改, 比如记录`在页5的偏移10处将值从0更新为1`
* 写入方式不同：
  * binlog 是**追加写**，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，**保存全量的日志**
  * redo log是**循环写**，日志空间大小是固定，全部写满就擦除从头开始，**保存未被刷入磁盘的脏页日志**

#### 两阶段提交

暂略

## SQL优化

### 慢SQL

#### 如何定位慢SQL

**方法一：**
慢SQL：MySQL中`long_query_time`默认值是10秒，即执行时间超过10秒的**SQL语句文本**会被记录到**慢查询日志**中(.log文件)
> 默认不开启，在配置文件中手动开启，以及自定义阈值
> **生产环境下超过1s就能算慢的了**

**方法二：**
通过`show profiles`命令查询当前会话中所有的sql语句的执行耗时情况，可以分析所有的语句，更强大
此外，通过`show profile for query queryId`命令可以查看指定sql的各个阶段的详细耗时时间（了解一下


定位到慢sql语句之后，

### explain执行计划



explain: 查看查询计划，可用于分析查询语句的性能瓶颈，找出慢SQL的原因

用法：`explain select * from table where id = 10;`


关注字段：

* `id`: 序列号，表示查询中执行select子句或操作表的顺序（id不同，值越大越先执行；id相同，执行顺序从上到下）（子查询、多表查询场景
* `select_type`: 查询类型
* ==type==: mysql在表中找到所需列的方式（连接类型
  * `NULL`: 性能最高，不查询表格时（笑
  * `system`: 访问系统表
  * `const`: 根据主键或唯一索引进行查询，一般是const
  * `ref`: 根据非唯一性索引查询进行查询时
  * `range`: 用了索引，只检索指定范围的行
  * `index`: 用了索引，但要扫描遍历整个索引树
  * `all`: 全表扫描，最慢
* key：实际用到的索引
* `extra`: 附加信息
  * `using index`: 表示查询的所有列都在索引中，避免了回表查询，使用**覆盖索引**
  * `using where`: 表示使用了where过滤，在从存储引擎检索行后，会对结果进行后续过滤（就非索引下推咯感觉是
  * `using index condition`: 使用了索引下推

（TODO 上面这俩依然需要整理 using where/index conditon

### 有哪些优化SQL的方式

[link](https://javabetter.cn/sidebar/sanfene/mysql.html#_25-%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E5%BC%8F%E4%BC%98%E5%8C%96-sql)

## 架构

### 基于binlog实现主从复制

复制的过程就是将 binlog 中的数据从主库传输到从库上（**异步**，不影响主库的操作）
![picture 5](../images/fe4ce4ca7fd69d8000d0cc10e049d378dc55a1352f00fae75e990414a316ef1d.png)  

具体详细过程如下：

* 主库master在收到客户端提交事务的请求之后，会**先写入binlog**，**再更新数据提交事务**，返回给客户端**操作成功**的响应。
* 从库slave会创建一个专门的**I/O线程**，连接主库的**log dump线程**，来接收主库的binlog日志，再把binlog信息写入**relay log**中继日志里，再返回给主库**复制成功**的响应。
* 从库会创建一个用于**回放binlog**的线程，去读relay log中继日志，然后回放binlog更新存储引擎中的数据，最终实现主从的数据一致性

在完成主从复制之后，你就可以**在写数据时只写主库，在读数据时只读从库**，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。（这不CopyOnWriteArrayList嘛

### 分库和分表是什么

分库分表：将原本存储在**单个数据库**中的数据分散到多个数据库中(分库), 将原本**单个表**中的数据分散到多个数据表中(分表)。通过这种方式, 可以提高数据库的查询性能和扩展性, 同时降低数据库的负载

* **分库**是一种**水平扩展数据库**的技术，将数据根据一定规则划分到多个独立的数据库中。**每个数据库只负责存储==部分数据==**，实现了数据的拆分和分布式存储。分库主要是为了解决并发连接过多，单机mysql扛不住的问题
* **分表**指的是将**单个数据库中的表拆分成多个表**，每个表只负责存储一部分数据。这种数据的**垂直划分**能够**提高查询效率，减轻单个表的压力**。分表主要是为了解决单表数据量太大，导致查询性能下降的问题

